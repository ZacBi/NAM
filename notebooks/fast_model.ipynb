{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3d7790b-0d6c-4be8-8eaa-d353005d5fc7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# FastModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a65c054-97d4-4a2d-b786-1f0d09deda06",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tmp code area\n",
    "# snapshot_download(sd_id, cache_dir = ckpt_base_pth, revision='v1.0.0') \n",
    "ds_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaa32bb-4725-43b7-9959-29206cd851b8",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee9ef5d-95f2-45d9-bfc7-f9f6265b17ce",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-05-04T11:13:18.901721Z",
     "iopub.status.busy": "2024-05-04T11:13:18.901144Z",
     "iopub.status.idle": "2024-05-04T11:13:18.905087Z",
     "shell.execute_reply": "2024-05-04T11:13:18.904690Z",
     "shell.execute_reply.started": "2024-05-04T11:13:18.901704Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "\n",
    "import random\n",
    "\n",
    "import pyarrow as pa\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.config import LazyConfig, instantiate\n",
    "from diffusers import AutoPipelineForText2Image\n",
    "from huggingface_hub import hf_hub_download\n",
    "from modelscope import AutoTokenizer\n",
    "from modelscope.hub.snapshot_download import snapshot_download\n",
    "from modelscope.models import Model\n",
    "from modelscope.msdatasets import MsDataset\n",
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.preprocessors import Preprocessor\n",
    "from modelscope.utils.constant import Tasks\n",
    "from transformers import AutoModel, LlamaModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab99b65-c3c9-48b5-b17a-97010b575604",
   "metadata": {},
   "source": [
    "## prepare datasource\n",
    "\n",
    "get dataset from [huggingface](https://huggingface.co/datasets/phiyodr/coco2017) or [modelScope](https://www.modelscope.cn/datasets/zacbi2023/coco2017_caption/summary)\n",
    "\n",
    "### huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b906f4-c4d3-4f2d-a571-e65faeaa9f94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hf_dataset = load_dataset(\"phiyodr/coco2017\")\n",
    "\n",
    "hf_ds_train = load_dataset(\"phiyodr/coco2017\", split=\"train\")\n",
    "hf_ds_validation = load_dataset(\"phiyodr/coco2017\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99eec6ab-e00a-4538-8490-c075a02bba18",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### modelscope\n",
    "\n",
    "The advantage of ModelScope is that it is very fast, after all, it is within the wall, and the disadvantage is that some datasets are incomplete, even if you call the official API and specify the source as HuggingFace, you may also generate an error.\n",
    "The solution here is to download the HuggingFace repo and then transfer it to Modelscope, which is very friendly for parquet type data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0919ca-ba8d-4562-9732-0999c168d859",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ms_ds_train = MsDataset.load('zacbi2023/coco2017_caption', subset_name='default', split='train')\n",
    "ms_ds_validation = MsDataset.load('zacbi2023/coco2017_caption', subset_name='default', split='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0261ab-3c26-4e69-b72d-74f01f58a395",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-05-04T11:09:44.828275Z",
     "iopub.status.busy": "2024-05-04T11:09:44.827403Z",
     "iopub.status.idle": "2024-05-04T11:09:44.833953Z",
     "shell.execute_reply": "2024-05-04T11:09:44.833553Z",
     "shell.execute_reply.started": "2024-05-04T11:09:44.828243Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "base_url = r'/mnt/workspace'\n",
    "ckpt_base_pth = path.join(base_url, 'model')\n",
    "llama_id = r'modelscope/Llama-2-7b-ms'\n",
    "sd_id = r'AI-ModelScope/stable-diffusion-2-1'\n",
    "llama_path = os.path.join(ckpt_base_pth, llama_id)\n",
    "sd_path = os.path.join(ckpt_base_pth, sd_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a7bf77-abea-4582-bb38-f03d149b376f",
   "metadata": {},
   "source": [
    "## Remap data\n",
    "\n",
    "All we need is to generate images of the horse, dog, and cat types, use simple tokenization, and then create a new database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af06fb0-1ed6-4cab-b73b-7ec7ae915c92",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(llama_path):\n",
    "    snapshot_download(llama_id, cache_dir = ckpt_base_pth)\n",
    "if not os.path.exists(sd_path):\n",
    "    snapshot_download(sd_id, cache_dir = ckpt_base_pth) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998ad635",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = AutoTokenizer.from_pretrained(\"sdfdsfe/bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a698a5-1bfb-43d6-a558-9f155f01c499",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "categories = set(['horse', 'dog', 'cat'])\n",
    "select_ds_cols = ['image_id', 'captions']\n",
    "def build_new_ds(dataset):\n",
    "    new_dataset = dataset.select_columns(select_ds_cols)\n",
    "    new_dataset = new_dataset.add_column(name = 'caption', column = [captions[max(range(len(captions)), key=lambda i: len(captions[i]))]  for captions in  dataset['captions']])\n",
    "    # new_dataset = new_dataset.add_column(name = 'last_hidden_state', column = [torch.zeros(1).numpy().tolist() for i in range(len(new_dataset))])\n",
    "    new_dataset = new_dataset.remove_columns(['captions'])\n",
    "\n",
    "    def add_tags(caption):\n",
    "        tags = []\n",
    "        tokennized_caption = set(bert_tokenizer.tokenize(caption))\n",
    "        for category in categories:\n",
    "            if category in tokennized_caption:\n",
    "                tags.append(category)\n",
    "        return tags\n",
    "    new_dataset = new_dataset.add_column(name = 'tags', column = [add_tags(caption) for caption in new_dataset['caption']])\n",
    "    new_dataset = new_dataset.filter(lambda x: len(x['tags']) > 0)\n",
    "\n",
    "    return new_dataset\n",
    "\n",
    "ds_train = build_new_ds(ms_ds_train)\n",
    "ds_train.features, ds_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7f1e86-d351-407a-8327-69264caec735",
   "metadata": {},
   "source": [
    "## accelerate infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa99752-a289-43e7-b2ad-073c196516ad",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-05-04T11:09:44.834914Z",
     "iopub.status.busy": "2024-05-04T11:09:44.834643Z",
     "iopub.status.idle": "2024-05-04T11:09:44.839027Z",
     "shell.execute_reply": "2024-05-04T11:09:44.838596Z",
     "shell.execute_reply.started": "2024-05-04T11:09:44.834893Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'gpu' if torch.cuda.is_available() else 'cpu'\n",
    "# device_map = '0'\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "# from_pretrained_dict = {'device_map': device_map, 'torch_dtype' : torch_dtype, 'revision': 'v1.0.1'}\n",
    "from_pretrained_dict = {'torch_dtype' : torch_dtype,  'variant': 'fp16'}\n",
    "\n",
    "def prompt_tensors_to_cuda(token_tensors):\n",
    "    for k, v in token_tensors.items():\n",
    "        token_tensors[k] = v.to('cuda')\n",
    "    return token_tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66514f43-a8e5-4f26-a328-36ae7b8e4659",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-04-05T12:23:18.983814Z",
     "iopub.status.busy": "2024-04-05T12:23:18.983210Z",
     "iopub.status.idle": "2024-04-05T12:23:18.990371Z",
     "shell.execute_reply": "2024-04-05T12:23:18.989271Z",
     "shell.execute_reply.started": "2024-04-05T12:23:18.983770Z"
    },
    "tags": []
   },
   "source": [
    "# LLama\n",
    "\n",
    "## Load model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3515172-5a0c-45fd-b70d-5332c6e1c147",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# llama\n",
    "# llama_model = LlamaModel.from_pretrained(llama_path, **from_pretrained_dict)\n",
    "llama_tokenizer = AutoTokenizer.from_pretrained(llama_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eeb870a-cb91-4766-9360-a5342330cf32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sd\n",
    "# stable_diffusion_model = Model.from_pretrained(sd_path, **from_pretrained_dict)\n",
    "\n",
    "prompt = ds_train['caption'][0]\n",
    "token_tensors = llama_tokenizer(prompt, return_tensors='pt')\n",
    "llama_outputs = llama_model(**prompt_tensors_to_cuda(token_tensors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666e07ac-0c91-4613-b21f-e859c9fa375d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llama_outputs.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a34650-32d5-4ce8-8d7d-057cdfa8d5a2",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-05-04T11:09:44.840461Z",
     "iopub.status.busy": "2024-05-04T11:09:44.840098Z",
     "iopub.status.idle": "2024-05-04T11:09:48.858289Z",
     "shell.execute_reply": "2024-05-04T11:09:48.857818Z",
     "shell.execute_reply.started": "2024-05-04T11:09:44.840440Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sd pipeline\n",
    "sd_pipeline = AutoPipelineForText2Image.from_pretrained(sd_path, **from_pretrained_dict).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72a4985-b30f-438d-b55a-08511a267297",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = ds_train['caption'][0]\n",
    "llama_tokenizer = AutoTokenizer.from_pretrained(llama_path)\n",
    "with torch.no_grad():\n",
    "    token_tensors = llama_tokenizer(prompt, return_tensors='pt')\n",
    "    llama_outputs = llama_model(**prompt_tensors_to_cuda(token_tensors))\n",
    "    prompt_embeds = outputs.last_hidden_state\n",
    "    sd_outputs = sd_pipeline(prompt_embeds=prompt_embeds)\n",
    "    sd_outputs.image[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adf98f4-c56f-4af4-b383-e9abbb7640e0",
   "metadata": {},
   "source": [
    "# Stable diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f476970-e499-43fa-980e-2aa6e8a07421",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-05-04T11:10:00.211021Z",
     "iopub.status.busy": "2024-05-04T11:10:00.210436Z",
     "iopub.status.idle": "2024-05-04T11:10:07.551121Z",
     "shell.execute_reply": "2024-05-04T11:10:07.550596Z",
     "shell.execute_reply.started": "2024-05-04T11:10:00.211003Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prompt = ds_train['caption'][0]\n",
    "prompt = 'A girl smiles as she holds a cat and wears a brightly colored skirt.'\n",
    "sd_output = sd_pipeline(prompt)\n",
    "images = sd_output.images\n",
    "image = images[0]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9774fce",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-05-04T11:14:10.106581Z",
     "iopub.status.busy": "2024-05-04T11:14:10.106013Z",
     "iopub.status.idle": "2024-05-04T11:14:10.123178Z",
     "shell.execute_reply": "2024-05-04T11:14:10.122725Z",
     "shell.execute_reply.started": "2024-05-04T11:14:10.106564Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_id = random.randint(1, 100000)\n",
    "image.save('/mnt/workspace/data/image/sd/output/eva_sd_{}.jpg'.format(image_id))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
