{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bee1a0f-019e-4965-86da-ff6df855d6c0",
   "metadata": {},
   "source": [
    "# Eva 02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cb82e8-606e-4ec4-9aae-b10b31fec35e",
   "metadata": {},
   "source": [
    "## prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2829133-425d-4c2f-81e7-79faf787c4a1",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-05-04T11:15:07.347556Z",
     "iopub.status.busy": "2024-05-04T11:15:07.347170Z",
     "iopub.status.idle": "2024-05-04T11:15:11.556092Z",
     "shell.execute_reply": "2024-05-04T11:15:11.555562Z",
     "shell.execute_reply.started": "2024-05-04T11:15:07.347540Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-05 09:58:30,020 - modelscope - INFO - PyTorch version 2.2.2+cu118 Found.\n",
      "2024-05-05 09:58:30,022 - modelscope - INFO - Loading ast index from /mnt/workspace/.cache/modelscope/ast_indexer\n",
      "2024-05-05 09:58:30,055 - modelscope - INFO - Loading done! Current index file version is 1.14.0, with md5 636cb37b3e5f290e6e650de7d45b396c and a total number of 976 components indexed\n"
     ]
    }
   ],
   "source": [
    "from os import path\n",
    "\n",
    "import torch\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.config import LazyConfig, get_cfg, instantiate\n",
    "from detectron2.data.detection_utils import read_image\n",
    "from detectron2.utils.visualizer import ColorMode, Visualizer\n",
    "from modelscope.hub.snapshot_download import snapshot_download\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b85d514f-9139-4c7f-9380-e1990e873e5e",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-05-04T11:15:14.654995Z",
     "iopub.status.busy": "2024-05-04T11:15:14.654356Z",
     "iopub.status.idle": "2024-05-04T11:15:14.661854Z",
     "shell.execute_reply": "2024-05-04T11:15:14.661404Z",
     "shell.execute_reply.started": "2024-05-04T11:15:14.654972Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_url = r'/mnt/workspace'\n",
    "ckpt_base_path = path.join(base_url, 'model')\n",
    "data_base_path = path.join(base_url, \"data\")\n",
    "\n",
    "# replace with your eva02 path \n",
    "eva02_modelscope_id = 'zacbi2023/eva02'\n",
    "eva02_base_path = path.join(ckpt_base_path, eva02_modelscope_id)\n",
    "\n",
    "# replace with your eva02 config path \n",
    "eva02_coco_config_rpath = 'projects/ViTDet/configs/eva2_o365_to_coco/eva2_o365_to_coco_cascade_mask_rcnn_vitdet_l_8attn_1536_lrd0p8.py'\n",
    "eva02_config_path = path.join(eva02_base_path, eva02_coco_config_rpath)\n",
    "\n",
    "# replace with your eva02 weights path \n",
    "eva02_coco_weights_rpth = 'checkpoints/eva02_L_coco_seg_sys_o365.pth'\n",
    "eva02_weights_path = path.join(eva02_base_path, eva02_coco_weights_rpth) \n",
    "\n",
    "# replace with your image_name\n",
    "image_name = 'eva_sd_61179.jpg'\n",
    "input_image_path = path.join(data_base_path, 'image/sd/output/', image_name)\n",
    "output_image_path = path.join(data_base_path, 'image/eva/output', image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bc4acd-fab3-4998-9799-0625e3284b0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-28T08:41:04.787757Z",
     "iopub.status.busy": "2024-04-28T08:41:04.787414Z",
     "iopub.status.idle": "2024-04-28T08:41:04.790383Z",
     "shell.execute_reply": "2024-04-28T08:41:04.789874Z",
     "shell.execute_reply.started": "2024-04-28T08:41:04.787735Z"
    },
    "tags": []
   },
   "source": [
    "### download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84537b91-398d-44c0-be8f-a7874b442eaa",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ignore semantic segmentation ckpt\n",
    "if not path.exists(eva02_base_path):\n",
    "    snapshot_download(eva02_modelscope_id, cache_dir = ckpt_base_path, ignore_file_pattern='eva02_L_ade_seg_upernet_sz640.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1c4b9a-0e24-438b-8232-424f9e74d36a",
   "metadata": {},
   "source": [
    "### config base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e00b7195-b64c-4557-9e86-1506e5fc9348",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-05-04T11:15:18.142508Z",
     "iopub.status.busy": "2024-05-04T11:15:18.141960Z",
     "iopub.status.idle": "2024-05-04T11:15:18.145054Z",
     "shell.execute_reply": "2024-05-04T11:15:18.144587Z",
     "shell.execute_reply.started": "2024-05-04T11:15:18.142490Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hardcode threshold\n",
    "config_file = eva02_config_path\n",
    "custum_cfg = ['MODEL.RETINANET.SCORE_THRESH_TEST', 0.5,\n",
    "              'MODEL.ROI_HEADS.SCORE_THRESH_TEST', 0.5,\n",
    "              'MODEL.PANOPTIC_FPN.COMBINE.INSTANCES_CONFIDENCE_THRESH', 0.5,\n",
    "              'DATASETS.TEST', [],\n",
    "            'MODEL.WEIGHTS', eva02_weights_path]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0123d242-252a-4201-bf1a-f2ad1f8fe2e8",
   "metadata": {},
   "source": [
    "### load via LazyConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cc8f316-a8f4-4e99-87b6-3931110b7144",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T11:15:21.349858Z",
     "iopub.status.busy": "2024-05-04T11:15:21.349291Z",
     "iopub.status.idle": "2024-05-04T11:15:21.506819Z",
     "shell.execute_reply": "2024-05-04T11:15:21.506365Z",
     "shell.execute_reply.started": "2024-05-04T11:15:21.349840Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataloader': {'train': {'dataset': {'names': 'coco_2017_train', '_target_': <function get_detection_dataset_dicts at 0x7fa243ef0820>}, 'mapper': {'is_train': True, 'augmentations': [{'horizontal': True, '_target_': <class 'detectron2.data.transforms.augmentation_impl.RandomFlip'>}, {'min_scale': 0.1, 'max_scale': 2.0, 'target_height': 1536, 'target_width': 1536, '_target_': <class 'detectron2.data.transforms.augmentation_impl.ResizeScale'>}, {'crop_size': [1536, 1536], 'pad': False, '_target_': <class 'detectron2.data.transforms.augmentation_impl.FixedSizeCrop'>}], 'image_format': 'RGB', 'use_instance_mask': True, '_target_': <class 'detectron2.data.dataset_mapper.DatasetMapper'>, 'recompute_boxes': True}, 'total_batch_size': 64, 'num_workers': 4, '_target_': <function build_detection_train_loader at 0x7fa243ef0af0>}, 'test': {'dataset': {'names': 'coco_2017_val', 'filter_empty': False, '_target_': <function get_detection_dataset_dicts at 0x7fa243ef0820>}, 'mapper': {'is_train': False, 'augmentations': [{'short_edge_length': 1536, 'max_size': 1536, '_target_': <class 'detectron2.data.transforms.augmentation_impl.ResizeShortestEdge'>}], 'image_format': '${...train.mapper.image_format}', '_target_': <class 'detectron2.data.dataset_mapper.DatasetMapper'>}, 'num_workers': 0, '_target_': <function build_detection_test_loader at 0x7fa243ef0ca0>}, 'evaluator': {'dataset_name': '${..test.dataset.names}', '_target_': <class 'detectron2.evaluation.coco_evaluation.COCOEvaluator'>}}, 'lr_multiplier': {'scheduler': {'start_value': 1, 'end_value': 1, '_target_': <class 'fvcore.common.param_scheduler.CosineParamScheduler'>}, 'warmup_length': 0.01, 'warmup_factor': 0.001, '_target_': <class 'detectron2.solver.lr_scheduler.WarmupParamScheduler'>}, 'model': {'backbone': {'net': {'img_size': 1536, 'patch_size': 16, 'embed_dim': 1024, 'depth': 24, 'num_heads': 16, 'drop_path_rate': 0.3, 'window_size': 16, 'mlp_ratio': 2.6666666666666665, 'qkv_bias': True, 'norm_layer': functools.partial(<class 'torch.nn.modules.normalization.LayerNorm'>, eps=1e-06), 'window_block_indexes': [0, 1, 3, 4, 6, 7, 9, 10, 12, 13, 15, 16, 18, 19, 21, 22], 'residual_block_indexes': [], 'use_rel_pos': True, 'out_feature': 'last_feat', '_target_': <class 'detectron2.modeling.backbone.vit.ViT'>, 'use_act_checkpoint': True}, 'in_feature': '${.net.out_feature}', 'out_channels': 256, 'scale_factors': [4.0, 2.0, 1.0, 0.5], 'top_block': {'_target_': <class 'detectron2.modeling.backbone.fpn.LastLevelMaxPool'>}, 'norm': 'LN', 'square_pad': 1536, '_target_': <class 'detectron2.modeling.backbone.vit.SimpleFeaturePyramid'>}, 'proposal_generator': {'in_features': ['p2', 'p3', 'p4', 'p5', 'p6'], 'head': {'in_channels': 256, 'num_anchors': 3, '_target_': <class 'detectron2.modeling.proposal_generator.rpn.StandardRPNHead'>, 'conv_dims': [-1, -1]}, 'anchor_generator': {'sizes': [[32], [64], [128], [256], [512]], 'aspect_ratios': [0.5, 1.0, 2.0], 'strides': [4, 8, 16, 32, 64], 'offset': 0.0, '_target_': <class 'detectron2.modeling.anchor_generator.DefaultAnchorGenerator'>}, 'anchor_matcher': {'thresholds': [0.3, 0.7], 'labels': [0, -1, 1], 'allow_low_quality_matches': True, '_target_': <class 'detectron2.modeling.matcher.Matcher'>}, 'box2box_transform': {'weights': [1.0, 1.0, 1.0, 1.0], '_target_': <class 'detectron2.modeling.box_regression.Box2BoxTransform'>}, 'batch_size_per_image': 256, 'positive_fraction': 0.5, 'pre_nms_topk': [2000, 1000], 'post_nms_topk': [1000, 1000], 'nms_thresh': 0.7, '_target_': <class 'detectron2.modeling.proposal_generator.rpn.RPN'>}, 'roi_heads': {'num_classes': 80, 'batch_size_per_image': 512, 'positive_fraction': 0.25, 'box_in_features': ['p2', 'p3', 'p4', 'p5'], 'box_pooler': {'output_size': 7, 'scales': [0.25, 0.125, 0.0625, 0.03125], 'sampling_ratio': 0, 'pooler_type': 'ROIAlignV2', '_target_': <class 'detectron2.modeling.poolers.ROIPooler'>}, 'mask_in_features': ['p2', 'p3', 'p4', 'p5'], 'mask_pooler': {'output_size': 14, 'scales': [0.25, 0.125, 0.0625, 0.03125], 'sampling_ratio': 0, 'pooler_type': 'ROIAlignV2', '_target_': <class 'detectron2.modeling.poolers.ROIPooler'>}, 'mask_head': {'input_shape': {'channels': 256, 'height': 14, 'width': 14, 'stride': None}, 'num_classes': '${..num_classes}', 'conv_dims': [256, 256, 256, 256, 256], '_target_': <class 'detectron2.modeling.roi_heads.mask_head.MaskRCNNConvUpsampleHead'>, 'conv_norm': 'LN'}, '_target_': <class 'detectron2.modeling.roi_heads.cascade_rcnn.CascadeROIHeads'>, 'box_heads': [{'input_shape': {'channels': 256, 'height': 7, 'width': 7, 'stride': None}, 'conv_dims': [256, 256, 256, 256], 'fc_dims': [1024], 'conv_norm': 'LN', '_target_': <class 'detectron2.modeling.roi_heads.box_head.FastRCNNConvFCHead'>}, {'input_shape': {'channels': 256, 'height': 7, 'width': 7, 'stride': None}, 'conv_dims': [256, 256, 256, 256], 'fc_dims': [1024], 'conv_norm': 'LN', '_target_': <class 'detectron2.modeling.roi_heads.box_head.FastRCNNConvFCHead'>}, {'input_shape': {'channels': 256, 'height': 7, 'width': 7, 'stride': None}, 'conv_dims': [256, 256, 256, 256], 'fc_dims': [1024], 'conv_norm': 'LN', '_target_': <class 'detectron2.modeling.roi_heads.box_head.FastRCNNConvFCHead'>}], 'box_predictors': [{'input_shape': {'channels': 1024, 'height': None, 'width': None, 'stride': None}, 'test_score_thresh': 0.05, 'box2box_transform': {'weights': [10, 10, 5, 5], '_target_': <class 'detectron2.modeling.box_regression.Box2BoxTransform'>}, 'cls_agnostic_bbox_reg': True, 'num_classes': '${...num_classes}', '_target_': <class 'detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers'>}, {'input_shape': {'channels': 1024, 'height': None, 'width': None, 'stride': None}, 'test_score_thresh': 0.05, 'box2box_transform': {'weights': [20, 20, 10, 10], '_target_': <class 'detectron2.modeling.box_regression.Box2BoxTransform'>}, 'cls_agnostic_bbox_reg': True, 'num_classes': '${...num_classes}', '_target_': <class 'detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers'>}, {'input_shape': {'channels': 1024, 'height': None, 'width': None, 'stride': None}, 'test_score_thresh': 0.05, 'box2box_transform': {'weights': [30, 30, 15, 15], '_target_': <class 'detectron2.modeling.box_regression.Box2BoxTransform'>}, 'cls_agnostic_bbox_reg': True, 'num_classes': '${...num_classes}', '_target_': <class 'detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers'>}], 'proposal_matchers': [{'thresholds': [0.5], 'labels': [0, 1], 'allow_low_quality_matches': False, '_target_': <class 'detectron2.modeling.matcher.Matcher'>}, {'thresholds': [0.6], 'labels': [0, 1], 'allow_low_quality_matches': False, '_target_': <class 'detectron2.modeling.matcher.Matcher'>}, {'thresholds': [0.7], 'labels': [0, 1], 'allow_low_quality_matches': False, '_target_': <class 'detectron2.modeling.matcher.Matcher'>}]}, 'pixel_mean': [123.675, 116.28, 103.53], 'pixel_std': [58.395, 57.12, 57.375], 'input_format': 'RGB', '_target_': <class 'detectron2.modeling.meta_arch.rcnn.GeneralizedRCNN'>}, 'train': {'output_dir': './output', 'init_checkpoint': 'detectron2://ImageNetPretrained/MAE/mae_pretrain_vit_base.pth', 'max_iter': 40000, 'amp': {'enabled': True}, 'ddp': {'broadcast_buffers': False, 'find_unused_parameters': False, 'fp16_compression': True}, 'checkpointer': {'period': 500, 'max_to_keep': 100}, 'eval_period': 500, 'log_period': 20, 'device': 'cuda', 'model_ema': {'enabled': True, 'decay': 0.9999, 'device': 'cuda', 'use_ema_weights_for_eval_only': False}}, 'optimizer': {'params': {'base_lr': '${..lr}', 'weight_decay_norm': None, '_target_': <function get_default_optimizer_params at 0x7fa2650f2ca0>, 'lr_factor_func': <function get_vit_lr_decay_rate at 0x7fa2650b0940>, 'overrides': {}}, 'lr': 4e-05, 'betas': [0.9, 0.999], 'weight_decay': 0.1, '_target_': <class 'torch.optim.adamw.AdamW'>}, 'MODEL': {'RETINANET': {'SCORE_THRESH_TEST': 0.5}, 'ROI_HEADS': {'SCORE_THRESH_TEST': 0.5}, 'PANOPTIC_FPN': {'COMBINE': {'INSTANCES_CONFIDENCE_THRESH': 0.5}}, 'WEIGHTS': '/mnt/workspace/model/zacbi2023/eva02/checkpoints/eva02_L_coco_seg_sys_o365.pth'}, 'DATASETS': {'TEST': []}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = LazyConfig.load(config_file)\n",
    "LazyConfig.apply_overrides(cfg, [f\"{key}={value}\" for key, value in zip(custum_cfg[::2], custum_cfg[1::2])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c6772f-e06b-4af8-bf94-aa8d6610bae1",
   "metadata": {},
   "source": [
    "### load via get_cfg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ea33916-adad-42e7-a377-44abf8dde4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not use!!!!\n",
    "# cfg = get_cfg()\n",
    "# cfg.merge_from_file(config_file)\n",
    "# cfg.merge_from_list([f\"{key}={value}\" for key, value in zip(custum_cfg[::2], custum_cfg[1::2])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9224bf0-f966-4d08-b070-7ef8d25c24a8",
   "metadata": {},
   "source": [
    "## Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd58e3f0-152e-4672-a492-3927a9175e9e",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-05-04T11:15:23.968825Z",
     "iopub.status.busy": "2024-05-04T11:15:23.968495Z",
     "iopub.status.idle": "2024-05-04T11:15:29.165171Z",
     "shell.execute_reply": "2024-05-04T11:15:29.164572Z",
     "shell.execute_reply.started": "2024-05-04T11:15:23.968806Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== shape of rope freq torch.Size([256, 64]) ========\n",
      "======== shape of rope freq torch.Size([9216, 64]) ========\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GeneralizedRCNN(\n",
       "  (backbone): SimpleFeaturePyramid(\n",
       "    (simfp_2): Sequential(\n",
       "      (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (1): LayerNorm()\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (4): Conv2d(\n",
       "        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "      (5): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (simfp_3): Sequential(\n",
       "      (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (1): Conv2d(\n",
       "        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "      (2): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (simfp_4): Sequential(\n",
       "      (0): Conv2d(\n",
       "        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "      (1): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (simfp_5): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(\n",
       "        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "      (2): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (net): ViT(\n",
       "      (patch_embed): PatchEmbed(\n",
       "        (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "      )\n",
       "      (rope_win): VisionRotaryEmbeddingFast()\n",
       "      (rope_glb): VisionRotaryEmbeddingFast()\n",
       "      (blocks): ModuleList(\n",
       "        (0): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.013)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.026)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.039)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.052)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.065)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.078)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.091)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.104)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.117)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.130)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.143)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.157)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (13): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.170)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (14): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.183)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.196)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.209)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (17): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.222)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (18): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.235)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (19): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.248)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (20): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.261)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (21): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.274)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (22): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.287)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (23): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.300)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (top_block): LastLevelMaxPool()\n",
       "  )\n",
       "  (proposal_generator): RPN(\n",
       "    (rpn_head): StandardRPNHead(\n",
       "      (conv): Sequential(\n",
       "        (conv0): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (conv1): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (anchor_generator): DefaultAnchorGenerator(\n",
       "      (cell_anchors): BufferList()\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): CascadeROIHeads(\n",
       "    (box_pooler): ROIPooler(\n",
       "      (level_poolers): ModuleList(\n",
       "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
       "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
       "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
       "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
       "      )\n",
       "    )\n",
       "    (box_head): ModuleList(\n",
       "      (0-2): 3 x FastRCNNConvFCHead(\n",
       "        (conv1): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (norm): LayerNorm()\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (conv2): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (norm): LayerNorm()\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (conv3): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (norm): LayerNorm()\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (conv4): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (norm): LayerNorm()\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "        (fc_relu1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (box_predictor): ModuleList(\n",
       "      (0-2): 3 x FastRCNNOutputLayers(\n",
       "        (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n",
       "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (mask_pooler): ROIPooler(\n",
       "      (level_poolers): ModuleList(\n",
       "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
       "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
       "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
       "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
       "      )\n",
       "    )\n",
       "    (mask_head): MaskRCNNConvUpsampleHead(\n",
       "      (mask_fcn1): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (mask_fcn2): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (mask_fcn3): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (mask_fcn4): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (deconv_relu): ReLU()\n",
       "      (predictor): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = instantiate(cfg.model)\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b43e979d-42c9-4bca-a219-aad722025ff2",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-05-04T11:15:29.166891Z",
     "iopub.status.busy": "2024-05-04T11:15:29.166331Z",
     "iopub.status.idle": "2024-05-04T11:15:30.236480Z",
     "shell.execute_reply": "2024-05-04T11:15:30.235914Z",
     "shell.execute_reply.started": "2024-05-04T11:15:29.166865Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mpixel_mean\u001b[0m\n",
      "  \u001b[35mpixel_std\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GeneralizedRCNN(\n",
       "  (backbone): SimpleFeaturePyramid(\n",
       "    (simfp_2): Sequential(\n",
       "      (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (1): LayerNorm()\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (4): Conv2d(\n",
       "        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "      (5): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (simfp_3): Sequential(\n",
       "      (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (1): Conv2d(\n",
       "        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "      (2): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (simfp_4): Sequential(\n",
       "      (0): Conv2d(\n",
       "        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "      (1): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (simfp_5): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(\n",
       "        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "      (2): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (net): ViT(\n",
       "      (patch_embed): PatchEmbed(\n",
       "        (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "      )\n",
       "      (rope_win): VisionRotaryEmbeddingFast()\n",
       "      (rope_glb): VisionRotaryEmbeddingFast()\n",
       "      (blocks): ModuleList(\n",
       "        (0): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.013)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.026)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.039)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.052)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.065)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.078)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.091)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.104)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.117)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.130)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.143)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.157)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (13): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.170)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (14): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.183)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.196)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.209)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (17): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.222)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (18): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.235)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (19): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.248)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (20): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.261)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (21): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.274)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (22): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.287)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (23): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.300)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (top_block): LastLevelMaxPool()\n",
       "  )\n",
       "  (proposal_generator): RPN(\n",
       "    (rpn_head): StandardRPNHead(\n",
       "      (conv): Sequential(\n",
       "        (conv0): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (conv1): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (anchor_generator): DefaultAnchorGenerator(\n",
       "      (cell_anchors): BufferList()\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): CascadeROIHeads(\n",
       "    (box_pooler): ROIPooler(\n",
       "      (level_poolers): ModuleList(\n",
       "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
       "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
       "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
       "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
       "      )\n",
       "    )\n",
       "    (box_head): ModuleList(\n",
       "      (0-2): 3 x FastRCNNConvFCHead(\n",
       "        (conv1): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (norm): LayerNorm()\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (conv2): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (norm): LayerNorm()\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (conv3): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (norm): LayerNorm()\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (conv4): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (norm): LayerNorm()\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "        (fc_relu1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (box_predictor): ModuleList(\n",
       "      (0-2): 3 x FastRCNNOutputLayers(\n",
       "        (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n",
       "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (mask_pooler): ROIPooler(\n",
       "      (level_poolers): ModuleList(\n",
       "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
       "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
       "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
       "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
       "      )\n",
       "    )\n",
       "    (mask_head): MaskRCNNConvUpsampleHead(\n",
       "      (mask_fcn1): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (mask_fcn2): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (mask_fcn3): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (mask_fcn4): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (deconv_relu): ReLU()\n",
       "      (predictor): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DetectionCheckpointer(model).load(eva02_weights_path)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7fa2ee8-1e5f-428f-8cb9-a5f0fe25b8ac",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-05-04T11:15:38.080271Z",
     "iopub.status.busy": "2024-05-04T11:15:38.079704Z",
     "iopub.status.idle": "2024-05-04T11:15:41.735281Z",
     "shell.execute_reply": "2024-05-04T11:15:41.734555Z",
     "shell.execute_reply.started": "2024-05-04T11:15:38.080253Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/eva/lib/python3.9/site-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3549.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "original_image = read_image(input_image_path, format=\"BGR\")\n",
    "height, width = original_image.shape[:2]\n",
    "image = torch.as_tensor(original_image.astype(\"float32\").transpose(2, 0, 1))\n",
    "inputs = {\"image\": image, \"height\": height, \"width\": width}\n",
    "predictions = model([inputs])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2d565fa-38e8-4bd2-be95-4c8485a34430",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'original_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m original_image \u001b[38;5;241m=\u001b[39m \u001b[43moriginal_image\u001b[49m[:, :, ::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'original_image' is not defined"
     ]
    }
   ],
   "source": [
    "original_image = original_image[:, :, ::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "185f91a9-0c26-453f-bf14-388d42e9e96a",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \n",
    "visualizer = Visualizer(original_image, None,\n",
    "                                instance_mode=ColorMode.IMAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a9fa71b-61c6-4946-98d0-dbd74dc7086b",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cpu_device = torch.device(\"cpu\")\n",
    "instances = predictions[\"instances\"].to(cpu_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a12811a-ef17-436f-86e0-37f36cfd1d72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \n",
    "vis_output = visualizer.draw_instance_predictions(\n",
    "                    predictions=instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62223e72-3c2c-47d2-b798-d0db315e1c2d",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save\n",
    "vis_output.save(output_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "672fcf62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Instances(num_instances=4, image_height=768, image_width=768, fields=[pred_boxes: Boxes(tensor([[2.0944e+02, 5.2295e+00, 5.7464e+02, 7.6118e+02],\n",
       "        [1.0083e+02, 3.3497e+02, 5.1348e+02, 6.7934e+02],\n",
       "        [1.0726e-01, 2.2810e+01, 4.3642e+01, 3.1540e+02],\n",
       "        [2.0703e+02, 5.0231e+00, 5.7440e+02, 7.6125e+02]], device='cuda:0',\n",
       "       grad_fn=<IndexBackward0>)), scores: tensor([0.9957, 0.9942, 0.0803, 0.0531], device='cuda:0',\n",
       "       grad_fn=<IndexBackward0>), pred_classes: tensor([ 0, 15, 26, 15], device='cuda:0'), pred_masks: tensor([[[False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "        [[False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "        [[False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "        [[False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False]]], device='cuda:0')])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instances = predictions['instances']\n",
    "instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9737498",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_masks = instances.pred_masks\n",
    "pred_classes = instances.pred_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d3838d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(234792, device='cuda:0'), tensor(234792, device='cuda:0'))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(pred_masks[1]) + torch.sum(pred_masks[3]), torch.sum(instances.pred_masks[instances.pred_classes == 15])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac7494d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02d9c78b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678ad88d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llava",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
