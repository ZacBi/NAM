{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bee1a0f-019e-4965-86da-ff6df855d6c0",
   "metadata": {},
   "source": [
    "# Eva 02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cb82e8-606e-4ec4-9aae-b10b31fec35e",
   "metadata": {},
   "source": [
    "## prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2829133-425d-4c2f-81e7-79faf787c4a1",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-05-17T15:00:03.784189Z",
     "iopub.status.busy": "2024-05-17T15:00:03.783796Z",
     "iopub.status.idle": "2024-05-17T15:00:05.008086Z",
     "shell.execute_reply": "2024-05-17T15:00:05.007506Z",
     "shell.execute_reply.started": "2024-05-17T15:00:03.784170Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'detectron2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m path\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdetectron2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpoint\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DetectionCheckpointer\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdetectron2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyConfig, get_cfg, instantiate\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdetectron2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdetection_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read_image\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'detectron2'"
     ]
    }
   ],
   "source": [
    "from os import path\n",
    "\n",
    "import torch\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.config import LazyConfig, get_cfg, instantiate\n",
    "from detectron2.data.detection_utils import read_image\n",
    "from detectron2.utils.visualizer import ColorMode, Visualizer\n",
    "from modelscope.hub.snapshot_download import snapshot_download\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b85d514f-9139-4c7f-9380-e1990e873e5e",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-05-17T13:43:05.873855Z",
     "iopub.status.busy": "2024-05-17T13:43:05.873374Z",
     "iopub.status.idle": "2024-05-17T13:43:05.877307Z",
     "shell.execute_reply": "2024-05-17T13:43:05.876841Z",
     "shell.execute_reply.started": "2024-05-17T13:43:05.873834Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_url = r'/mnt/workspace'\n",
    "ckpt_base_path = path.join(base_url, 'model')\n",
    "data_base_path = path.join(base_url, \"data\")\n",
    "\n",
    "# replace with your eva02 path \n",
    "eva02_modelscope_id = 'zacbi2023/eva02'\n",
    "eva02_base_path = path.join(ckpt_base_path, eva02_modelscope_id)\n",
    "\n",
    "# replace with your eva02 config path \n",
    "eva02_coco_config_rpath = 'projects/ViTDet/configs/eva2_o365_to_coco/eva2_o365_to_coco_cascade_mask_rcnn_vitdet_l_8attn_1536_lrd0p8.py'\n",
    "eva02_config_path = path.join(eva02_base_path, eva02_coco_config_rpath)\n",
    "\n",
    "# replace with your eva02 weights path \n",
    "eva02_coco_weights_rpth = 'checkpoints/eva02_L_coco_seg_sys_o365.pth'\n",
    "eva02_weights_path = path.join(eva02_base_path, eva02_coco_weights_rpth) \n",
    "\n",
    "# replace with your image_name\n",
    "image_name = 'eva_sd_61179.jpg'\n",
    "input_image_path = path.join(data_base_path, 'image/sd/output/', image_name)\n",
    "output_image_path = path.join(data_base_path, 'image/eva/output', image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bc4acd-fab3-4998-9799-0625e3284b0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-28T08:41:04.787757Z",
     "iopub.status.busy": "2024-04-28T08:41:04.787414Z",
     "iopub.status.idle": "2024-04-28T08:41:04.790383Z",
     "shell.execute_reply": "2024-04-28T08:41:04.789874Z",
     "shell.execute_reply.started": "2024-04-28T08:41:04.787735Z"
    },
    "tags": []
   },
   "source": [
    "### download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84537b91-398d-44c0-be8f-a7874b442eaa",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ignore semantic segmentation ckpt\n",
    "if not path.exists(eva02_base_path):\n",
    "    snapshot_download(eva02_modelscope_id, cache_dir = ckpt_base_path, ignore_file_pattern='eva02_L_ade_seg_upernet_sz640.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1c4b9a-0e24-438b-8232-424f9e74d36a",
   "metadata": {},
   "source": [
    "### config base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e00b7195-b64c-4557-9e86-1506e5fc9348",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-05-17T13:43:08.915059Z",
     "iopub.status.busy": "2024-05-17T13:43:08.914745Z",
     "iopub.status.idle": "2024-05-17T13:43:08.917765Z",
     "shell.execute_reply": "2024-05-17T13:43:08.917271Z",
     "shell.execute_reply.started": "2024-05-17T13:43:08.915040Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hardcode threshold\n",
    "config_file = eva02_config_path\n",
    "custum_cfg = ['MODEL.RETINANET.SCORE_THRESH_TEST', 0.5,\n",
    "              'MODEL.ROI_HEADS.SCORE_THRESH_TEST', 0.5,\n",
    "              'MODEL.PANOPTIC_FPN.COMBINE.INSTANCES_CONFIDENCE_THRESH', 0.5,\n",
    "              'DATASETS.TEST', [],\n",
    "            'MODEL.WEIGHTS', eva02_weights_path]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0123d242-252a-4201-bf1a-f2ad1f8fe2e8",
   "metadata": {},
   "source": [
    "### load via LazyConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cc8f316-a8f4-4e99-87b6-3931110b7144",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-17T13:43:12.040363Z",
     "iopub.status.busy": "2024-05-17T13:43:12.040052Z",
     "iopub.status.idle": "2024-05-17T13:43:12.235761Z",
     "shell.execute_reply": "2024-05-17T13:43:12.235340Z",
     "shell.execute_reply.started": "2024-05-17T13:43:12.040345Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataloader': {'train': {'dataset': {'names': 'coco_2017_train', '_target_': <function get_detection_dataset_dicts at 0x7f7f7abcf370>}, 'mapper': {'is_train': True, 'augmentations': [{'horizontal': True, '_target_': <class 'detectron2.data.transforms.augmentation_impl.RandomFlip'>}, {'min_scale': 0.1, 'max_scale': 2.0, 'target_height': 1536, 'target_width': 1536, '_target_': <class 'detectron2.data.transforms.augmentation_impl.ResizeScale'>}, {'crop_size': [1536, 1536], 'pad': False, '_target_': <class 'detectron2.data.transforms.augmentation_impl.FixedSizeCrop'>}], 'image_format': 'RGB', 'use_instance_mask': True, '_target_': <class 'detectron2.data.dataset_mapper.DatasetMapper'>, 'recompute_boxes': True}, 'total_batch_size': 64, 'num_workers': 4, '_target_': <function build_detection_train_loader at 0x7f7f7abcf760>}, 'test': {'dataset': {'names': 'coco_2017_val', 'filter_empty': False, '_target_': <function get_detection_dataset_dicts at 0x7f7f7abcf370>}, 'mapper': {'is_train': False, 'augmentations': [{'short_edge_length': 1536, 'max_size': 1536, '_target_': <class 'detectron2.data.transforms.augmentation_impl.ResizeShortestEdge'>}], 'image_format': '${...train.mapper.image_format}', '_target_': <class 'detectron2.data.dataset_mapper.DatasetMapper'>}, 'num_workers': 0, '_target_': <function build_detection_test_loader at 0x7f7f7abcf910>}, 'evaluator': {'dataset_name': '${..test.dataset.names}', '_target_': <class 'detectron2.evaluation.coco_evaluation.COCOEvaluator'>}}, 'lr_multiplier': {'scheduler': {'start_value': 1, 'end_value': 1, '_target_': <class 'fvcore.common.param_scheduler.CosineParamScheduler'>}, 'warmup_length': 0.01, 'warmup_factor': 0.001, '_target_': <class 'detectron2.solver.lr_scheduler.WarmupParamScheduler'>}, 'model': {'backbone': {'net': {'img_size': 1536, 'patch_size': 16, 'embed_dim': 1024, 'depth': 24, 'num_heads': 16, 'drop_path_rate': 0.3, 'window_size': 16, 'mlp_ratio': 2.6666666666666665, 'qkv_bias': True, 'norm_layer': functools.partial(<class 'torch.nn.modules.normalization.LayerNorm'>, eps=1e-06), 'window_block_indexes': [0, 1, 3, 4, 6, 7, 9, 10, 12, 13, 15, 16, 18, 19, 21, 22], 'residual_block_indexes': [], 'use_rel_pos': True, 'out_feature': 'last_feat', '_target_': <class 'detectron2.modeling.backbone.vit.ViT'>, 'use_act_checkpoint': True}, 'in_feature': '${.net.out_feature}', 'out_channels': 256, 'scale_factors': [4.0, 2.0, 1.0, 0.5], 'top_block': {'_target_': <class 'detectron2.modeling.backbone.fpn.LastLevelMaxPool'>}, 'norm': 'LN', 'square_pad': 1536, '_target_': <class 'detectron2.modeling.backbone.vit.SimpleFeaturePyramid'>}, 'proposal_generator': {'in_features': ['p2', 'p3', 'p4', 'p5', 'p6'], 'head': {'in_channels': 256, 'num_anchors': 3, '_target_': <class 'detectron2.modeling.proposal_generator.rpn.StandardRPNHead'>, 'conv_dims': [-1, -1]}, 'anchor_generator': {'sizes': [[32], [64], [128], [256], [512]], 'aspect_ratios': [0.5, 1.0, 2.0], 'strides': [4, 8, 16, 32, 64], 'offset': 0.0, '_target_': <class 'detectron2.modeling.anchor_generator.DefaultAnchorGenerator'>}, 'anchor_matcher': {'thresholds': [0.3, 0.7], 'labels': [0, -1, 1], 'allow_low_quality_matches': True, '_target_': <class 'detectron2.modeling.matcher.Matcher'>}, 'box2box_transform': {'weights': [1.0, 1.0, 1.0, 1.0], '_target_': <class 'detectron2.modeling.box_regression.Box2BoxTransform'>}, 'batch_size_per_image': 256, 'positive_fraction': 0.5, 'pre_nms_topk': [2000, 1000], 'post_nms_topk': [1000, 1000], 'nms_thresh': 0.7, '_target_': <class 'detectron2.modeling.proposal_generator.rpn.RPN'>}, 'roi_heads': {'num_classes': 80, 'batch_size_per_image': 512, 'positive_fraction': 0.25, 'box_in_features': ['p2', 'p3', 'p4', 'p5'], 'box_pooler': {'output_size': 7, 'scales': [0.25, 0.125, 0.0625, 0.03125], 'sampling_ratio': 0, 'pooler_type': 'ROIAlignV2', '_target_': <class 'detectron2.modeling.poolers.ROIPooler'>}, 'mask_in_features': ['p2', 'p3', 'p4', 'p5'], 'mask_pooler': {'output_size': 14, 'scales': [0.25, 0.125, 0.0625, 0.03125], 'sampling_ratio': 0, 'pooler_type': 'ROIAlignV2', '_target_': <class 'detectron2.modeling.poolers.ROIPooler'>}, 'mask_head': {'input_shape': {'channels': 256, 'height': 14, 'width': 14, 'stride': None}, 'num_classes': '${..num_classes}', 'conv_dims': [256, 256, 256, 256, 256], '_target_': <class 'detectron2.modeling.roi_heads.mask_head.MaskRCNNConvUpsampleHead'>, 'conv_norm': 'LN'}, '_target_': <class 'detectron2.modeling.roi_heads.cascade_rcnn.CascadeROIHeads'>, 'box_heads': [{'input_shape': {'channels': 256, 'height': 7, 'width': 7, 'stride': None}, 'conv_dims': [256, 256, 256, 256], 'fc_dims': [1024], 'conv_norm': 'LN', '_target_': <class 'detectron2.modeling.roi_heads.box_head.FastRCNNConvFCHead'>}, {'input_shape': {'channels': 256, 'height': 7, 'width': 7, 'stride': None}, 'conv_dims': [256, 256, 256, 256], 'fc_dims': [1024], 'conv_norm': 'LN', '_target_': <class 'detectron2.modeling.roi_heads.box_head.FastRCNNConvFCHead'>}, {'input_shape': {'channels': 256, 'height': 7, 'width': 7, 'stride': None}, 'conv_dims': [256, 256, 256, 256], 'fc_dims': [1024], 'conv_norm': 'LN', '_target_': <class 'detectron2.modeling.roi_heads.box_head.FastRCNNConvFCHead'>}], 'box_predictors': [{'input_shape': {'channels': 1024, 'height': None, 'width': None, 'stride': None}, 'test_score_thresh': 0.05, 'box2box_transform': {'weights': [10, 10, 5, 5], '_target_': <class 'detectron2.modeling.box_regression.Box2BoxTransform'>}, 'cls_agnostic_bbox_reg': True, 'num_classes': '${...num_classes}', '_target_': <class 'detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers'>}, {'input_shape': {'channels': 1024, 'height': None, 'width': None, 'stride': None}, 'test_score_thresh': 0.05, 'box2box_transform': {'weights': [20, 20, 10, 10], '_target_': <class 'detectron2.modeling.box_regression.Box2BoxTransform'>}, 'cls_agnostic_bbox_reg': True, 'num_classes': '${...num_classes}', '_target_': <class 'detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers'>}, {'input_shape': {'channels': 1024, 'height': None, 'width': None, 'stride': None}, 'test_score_thresh': 0.05, 'box2box_transform': {'weights': [30, 30, 15, 15], '_target_': <class 'detectron2.modeling.box_regression.Box2BoxTransform'>}, 'cls_agnostic_bbox_reg': True, 'num_classes': '${...num_classes}', '_target_': <class 'detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers'>}], 'proposal_matchers': [{'thresholds': [0.5], 'labels': [0, 1], 'allow_low_quality_matches': False, '_target_': <class 'detectron2.modeling.matcher.Matcher'>}, {'thresholds': [0.6], 'labels': [0, 1], 'allow_low_quality_matches': False, '_target_': <class 'detectron2.modeling.matcher.Matcher'>}, {'thresholds': [0.7], 'labels': [0, 1], 'allow_low_quality_matches': False, '_target_': <class 'detectron2.modeling.matcher.Matcher'>}]}, 'pixel_mean': [123.675, 116.28, 103.53], 'pixel_std': [58.395, 57.12, 57.375], 'input_format': 'RGB', '_target_': <class 'detectron2.modeling.meta_arch.rcnn.GeneralizedRCNN'>}, 'train': {'output_dir': './output', 'init_checkpoint': 'detectron2://ImageNetPretrained/MAE/mae_pretrain_vit_base.pth', 'max_iter': 40000, 'amp': {'enabled': True}, 'ddp': {'broadcast_buffers': False, 'find_unused_parameters': False, 'fp16_compression': True}, 'checkpointer': {'period': 5000, 'max_to_keep': 100}, 'eval_period': 5000, 'log_period': 20, 'device': 'cuda', 'model_ema': {'enabled': True, 'device': 'cuda', 'decay': 0.9999}}, 'optimizer': {'params': {'base_lr': '${..lr}', 'weight_decay_norm': None, '_target_': <function get_default_optimizer_params at 0x7f7f6c9463b0>, 'lr_factor_func': <function get_vit_lr_decay_rate at 0x7f7f6ca4d090>, 'overrides': {}}, 'lr': 4e-05, 'betas': [0.9, 0.999], 'weight_decay': 0.1, '_target_': <class 'torch.optim.adamw.AdamW'>}, 'MODEL': {'RETINANET': {'SCORE_THRESH_TEST': 0.5}, 'ROI_HEADS': {'SCORE_THRESH_TEST': 0.5}, 'PANOPTIC_FPN': {'COMBINE': {'INSTANCES_CONFIDENCE_THRESH': 0.5}}, 'WEIGHTS': '/mnt/workspace/model/zacbi2023/eva02/checkpoints/eva02_L_coco_seg_sys_o365.pth'}, 'DATASETS': {'TEST': []}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = LazyConfig.load(config_file)\n",
    "LazyConfig.apply_overrides(cfg, [f\"{key}={value}\" for key, value in zip(custum_cfg[::2], custum_cfg[1::2])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c6772f-e06b-4af8-bf94-aa8d6610bae1",
   "metadata": {},
   "source": [
    "### load via get_cfg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ea33916-adad-42e7-a377-44abf8dde4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not use!!!!\n",
    "# cfg = get_cfg()\n",
    "# cfg.merge_from_file(config_file)\n",
    "# cfg.merge_from_list([f\"{key}={value}\" for key, value in zip(custum_cfg[::2], custum_cfg[1::2])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9224bf0-f966-4d08-b070-7ef8d25c24a8",
   "metadata": {},
   "source": [
    "## Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd58e3f0-152e-4672-a492-3927a9175e9e",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-05-17T13:43:15.528297Z",
     "iopub.status.busy": "2024-05-17T13:43:15.527982Z",
     "iopub.status.idle": "2024-05-17T13:43:18.869515Z",
     "shell.execute_reply": "2024-05-17T13:43:18.869081Z",
     "shell.execute_reply.started": "2024-05-17T13:43:15.528278Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GeneralizedRCNN(\n",
       "  (backbone): SimpleFeaturePyramid(\n",
       "    (simfp_2): Sequential(\n",
       "      (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (1): LayerNorm()\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (4): Conv2d(\n",
       "        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "      (5): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (simfp_3): Sequential(\n",
       "      (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (1): Conv2d(\n",
       "        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "      (2): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (simfp_4): Sequential(\n",
       "      (0): Conv2d(\n",
       "        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "      (1): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (simfp_5): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(\n",
       "        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "      (2): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (net): ViT(\n",
       "      (patch_embed): PatchEmbed(\n",
       "        (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "      )\n",
       "      (blocks): ModuleList(\n",
       "        (0): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.013)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.026)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.039)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.052)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.065)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.078)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.091)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.104)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.117)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.130)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.143)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.157)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (13): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.170)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (14): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.183)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.196)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.209)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (17): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.222)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (18): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.235)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (19): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.248)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (20): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.261)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (21): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.274)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (22): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.287)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (23): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.300)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (top_block): LastLevelMaxPool()\n",
       "  )\n",
       "  (proposal_generator): RPN(\n",
       "    (rpn_head): StandardRPNHead(\n",
       "      (conv): Sequential(\n",
       "        (conv0): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (conv1): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (anchor_generator): DefaultAnchorGenerator(\n",
       "      (cell_anchors): BufferList()\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): CascadeROIHeads(\n",
       "    (box_pooler): ROIPooler(\n",
       "      (level_poolers): ModuleList(\n",
       "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
       "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
       "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
       "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
       "      )\n",
       "    )\n",
       "    (box_head): ModuleList(\n",
       "      (0-2): 3 x FastRCNNConvFCHead(\n",
       "        (conv1): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (norm): LayerNorm()\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (conv2): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (norm): LayerNorm()\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (conv3): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (norm): LayerNorm()\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (conv4): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (norm): LayerNorm()\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "        (fc_relu1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (box_predictor): ModuleList(\n",
       "      (0-2): 3 x FastRCNNOutputLayers(\n",
       "        (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n",
       "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (mask_pooler): ROIPooler(\n",
       "      (level_poolers): ModuleList(\n",
       "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
       "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
       "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
       "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
       "      )\n",
       "    )\n",
       "    (mask_head): MaskRCNNConvUpsampleHead(\n",
       "      (mask_fcn1): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (mask_fcn2): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (mask_fcn3): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (mask_fcn4): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (deconv_relu): ReLU()\n",
       "      (predictor): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = instantiate(cfg.model)\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b43e979d-42c9-4bca-a219-aad722025ff2",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-05-04T11:15:29.166891Z",
     "iopub.status.busy": "2024-05-04T11:15:29.166331Z",
     "iopub.status.idle": "2024-05-04T11:15:30.236480Z",
     "shell.execute_reply": "2024-05-04T11:15:30.235914Z",
     "shell.execute_reply.started": "2024-05-04T11:15:29.166865Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mpixel_mean\u001b[0m\n",
      "  \u001b[35mpixel_std\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GeneralizedRCNN(\n",
       "  (backbone): SimpleFeaturePyramid(\n",
       "    (simfp_2): Sequential(\n",
       "      (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (1): LayerNorm()\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (4): Conv2d(\n",
       "        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "      (5): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (simfp_3): Sequential(\n",
       "      (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (1): Conv2d(\n",
       "        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "      (2): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (simfp_4): Sequential(\n",
       "      (0): Conv2d(\n",
       "        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "      (1): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (simfp_5): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(\n",
       "        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "      (2): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (net): ViT(\n",
       "      (patch_embed): PatchEmbed(\n",
       "        (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "      )\n",
       "      (rope_win): VisionRotaryEmbeddingFast()\n",
       "      (rope_glb): VisionRotaryEmbeddingFast()\n",
       "      (blocks): ModuleList(\n",
       "        (0): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.013)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.026)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.039)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.052)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.065)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.078)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.091)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.104)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.117)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.130)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.143)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.157)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (13): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.170)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (14): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.183)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.196)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.209)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (17): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.222)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (18): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.235)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (19): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.248)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (20): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.261)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (21): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.274)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (22): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.287)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (23): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.300)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (top_block): LastLevelMaxPool()\n",
       "  )\n",
       "  (proposal_generator): RPN(\n",
       "    (rpn_head): StandardRPNHead(\n",
       "      (conv): Sequential(\n",
       "        (conv0): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (conv1): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (anchor_generator): DefaultAnchorGenerator(\n",
       "      (cell_anchors): BufferList()\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): CascadeROIHeads(\n",
       "    (box_pooler): ROIPooler(\n",
       "      (level_poolers): ModuleList(\n",
       "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
       "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
       "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
       "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
       "      )\n",
       "    )\n",
       "    (box_head): ModuleList(\n",
       "      (0-2): 3 x FastRCNNConvFCHead(\n",
       "        (conv1): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (norm): LayerNorm()\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (conv2): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (norm): LayerNorm()\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (conv3): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (norm): LayerNorm()\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (conv4): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (norm): LayerNorm()\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "        (fc_relu1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (box_predictor): ModuleList(\n",
       "      (0-2): 3 x FastRCNNOutputLayers(\n",
       "        (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n",
       "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (mask_pooler): ROIPooler(\n",
       "      (level_poolers): ModuleList(\n",
       "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
       "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
       "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
       "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
       "      )\n",
       "    )\n",
       "    (mask_head): MaskRCNNConvUpsampleHead(\n",
       "      (mask_fcn1): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (mask_fcn2): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (mask_fcn3): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (mask_fcn4): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (deconv_relu): ReLU()\n",
       "      (predictor): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DetectionCheckpointer(model).load(eva02_weights_path)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7fa2ee8-1e5f-428f-8cb9-a5f0fe25b8ac",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-05-17T13:45:27.909049Z",
     "iopub.status.busy": "2024-05-17T13:45:27.908717Z",
     "iopub.status.idle": "2024-05-17T13:45:29.741917Z",
     "shell.execute_reply": "2024-05-17T13:45:29.741211Z",
     "shell.execute_reply.started": "2024-05-17T13:45:27.909028Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 5.06 GiB. GPU 0 has a total capacty of 22.20 GiB of which 4.68 GiB is free. Process 31818 has 17.52 GiB memory in use. Of the allocated memory 12.14 GiB is allocated by PyTorch, and 5.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m image \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(original_image\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat16\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m      4\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m: image, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheight\u001b[39m\u001b[38;5;124m\"\u001b[39m: height, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m\"\u001b[39m: width}\n\u001b[0;32m----> 5\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/detectron2/modeling/meta_arch/rcnn.py:158\u001b[0m, in \u001b[0;36mGeneralizedRCNN.forward\u001b[0;34m(self, batched_inputs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    156\u001b[0m     gt_instances \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproposal_generator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     proposals, proposal_losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproposal_generator(images, features, gt_instances)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/detectron2/modeling/backbone/vit.py:489\u001b[0m, in \u001b[0;36mSimpleFeaturePyramid.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    478\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;124;03m        x: Tensor of shape (N,C,H,W). H, W must be a multiple of ``self.size_divisibility``.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;124;03m            [\"p2\", \"p3\", ..., \"p6\"].\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 489\u001b[0m     bottom_up_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    490\u001b[0m     features \u001b[38;5;241m=\u001b[39m bottom_up_features[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_feature]\n\u001b[1;32m    491\u001b[0m     results \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/detectron2/modeling/backbone/vit.py:357\u001b[0m, in \u001b[0;36mViT.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    352\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m get_abs_pos(\n\u001b[1;32m    353\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_embed, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpretrain_use_cls_token, (x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m    354\u001b[0m     )\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m--> 357\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    359\u001b[0m outputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_out_features[\u001b[38;5;241m0\u001b[39m]: x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)}\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/fairscale/nn/checkpoint/checkpoint_activations.py:191\u001b[0m, in \u001b[0;36m_checkpointed_forward\u001b[0;34m(original_forward, weak_self, offload_to_cpu, *args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m parent_ctx_dict: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moffload\u001b[39m\u001b[38;5;124m\"\u001b[39m: offload_to_cpu,\n\u001b[1;32m    180\u001b[0m }\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m# Dummy tensor with grad is used to ensure the backward pass is called. This is needed\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# when original_forward's input are non-tensor (i.e. a tuple). Using this dummy tensor\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;66;03m# avoids requiring users to set their input tensors's requires_grad flag. In the case\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# We get around this by saving the desired requires_grad value in output and\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# detaching the output if needed.\u001b[39;00m\n\u001b[0;32m--> 191\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mCheckpointFunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequires_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent_ctx_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwarg_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflat_args\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m output_requires_grad \u001b[38;5;241m=\u001b[39m parent_ctx_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_requires_grad\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;66;03m# If output should not require grad, then detach it, since otherwise it will\u001b[39;00m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;66;03m# always have requires_grad = True due to our dummy tensor input above that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;66;03m# requires_grad\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/function.py:539\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    538\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39msetup_context \u001b[38;5;241m==\u001b[39m _SingleLevelFunction\u001b[38;5;241m.\u001b[39msetup_context:\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    543\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    544\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    545\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    546\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    547\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/fairscale/nn/checkpoint/checkpoint_activations.py:283\u001b[0m, in \u001b[0;36mCheckpointFunction.forward\u001b[0;34m(ctx, dummy_tensor_requires_grad, run_function, parent_ctx_dict, kwarg_keys, *args, **kwargs)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(), enable_checkpointing():\n\u001b[1;32m    282\u001b[0m     unpacked_args, unpacked_kwargs \u001b[38;5;241m=\u001b[39m unpack_kwargs(kwarg_keys, args)\n\u001b[0;32m--> 283\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mrun_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43munpacked_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43munpacked_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m     the_module \u001b[38;5;241m=\u001b[39m unpacked_args[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# Because we run with torch.no_grad(), we can't actually access\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# outputs.requires_grad. Instead, we manually compute it by\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# checking if either the input or the module needs grads\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/detectron2/modeling/backbone/vit.py:218\u001b[0m, in \u001b[0;36mBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    215\u001b[0m     H, W \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    216\u001b[0m     x, pad_hw \u001b[38;5;241m=\u001b[39m window_partition(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_size)\n\u001b[0;32m--> 218\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# Reverse window partition\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/detectron2/modeling/backbone/vit.py:75\u001b[0m, in \u001b[0;36mAttention.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     72\u001b[0m attn \u001b[38;5;241m=\u001b[39m (q \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale) \u001b[38;5;241m@\u001b[39m k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_rel_pos:\n\u001b[0;32m---> 75\u001b[0m     attn \u001b[38;5;241m=\u001b[39m \u001b[43madd_decomposed_rel_pos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrel_pos_h\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrel_pos_w\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m attn \u001b[38;5;241m=\u001b[39m attn\u001b[38;5;241m.\u001b[39msoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     78\u001b[0m x \u001b[38;5;241m=\u001b[39m (attn \u001b[38;5;241m@\u001b[39m v)\u001b[38;5;241m.\u001b[39mview(B, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, H, W, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(B, H, W, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/detectron2/modeling/backbone/utils.py:122\u001b[0m, in \u001b[0;36madd_decomposed_rel_pos\u001b[0;34m(attn, q, rel_pos_h, rel_pos_w, q_size, k_size)\u001b[0m\n\u001b[1;32m    118\u001b[0m rel_h \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbhwc,hkc->bhwk\u001b[39m\u001b[38;5;124m\"\u001b[39m, r_q, Rh)\n\u001b[1;32m    119\u001b[0m rel_w \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbhwc,wkc->bhwk\u001b[39m\u001b[38;5;124m\"\u001b[39m, r_q, Rw)\n\u001b[1;32m    121\u001b[0m attn \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 122\u001b[0m     \u001b[43mattn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq_h\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq_w\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_h\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_w\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrel_h\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrel_w\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    123\u001b[0m )\u001b[38;5;241m.\u001b[39mview(B, q_h \u001b[38;5;241m*\u001b[39m q_w, k_h \u001b[38;5;241m*\u001b[39m k_w)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m attn\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 5.06 GiB. GPU 0 has a total capacty of 22.20 GiB of which 4.68 GiB is free. Process 31818 has 17.52 GiB memory in use. Of the allocated memory 12.14 GiB is allocated by PyTorch, and 5.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "original_image = read_image(input_image_path, format=\"BGR\")\n",
    "height, width = original_image.shape[:2]\n",
    "image = torch.as_tensor(original_image.astype(\"float16\").transpose(2, 0, 1))\n",
    "inputs = {\"image\": image, \"height\": height, \"width\": width}\n",
    "predictions = model([inputs])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2d565fa-38e8-4bd2-be95-4c8485a34430",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'original_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m original_image \u001b[38;5;241m=\u001b[39m \u001b[43moriginal_image\u001b[49m[:, :, ::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'original_image' is not defined"
     ]
    }
   ],
   "source": [
    "original_image = original_image[:, :, ::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "185f91a9-0c26-453f-bf14-388d42e9e96a",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 可视化器\n",
    "visualizer = Visualizer(original_image, None,\n",
    "                                instance_mode=ColorMode.IMAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a9fa71b-61c6-4946-98d0-dbd74dc7086b",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cpu_device = torch.device(\"cpu\")\n",
    "instances = predictions[\"instances\"].to(cpu_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a12811a-ef17-436f-86e0-37f36cfd1d72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 可视化输出\n",
    "vis_output = visualizer.draw_instance_predictions(\n",
    "                    predictions=instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62223e72-3c2c-47d2-b798-d0db315e1c2d",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save\n",
    "vis_output.save(output_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "672fcf62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Instances(num_instances=4, image_height=768, image_width=768, fields=[pred_boxes: Boxes(tensor([[2.0944e+02, 5.2295e+00, 5.7464e+02, 7.6118e+02],\n",
       "        [1.0083e+02, 3.3497e+02, 5.1348e+02, 6.7934e+02],\n",
       "        [1.0726e-01, 2.2810e+01, 4.3642e+01, 3.1540e+02],\n",
       "        [2.0703e+02, 5.0231e+00, 5.7440e+02, 7.6125e+02]], device='cuda:0',\n",
       "       grad_fn=<IndexBackward0>)), scores: tensor([0.9957, 0.9942, 0.0803, 0.0531], device='cuda:0',\n",
       "       grad_fn=<IndexBackward0>), pred_classes: tensor([ 0, 15, 26, 15], device='cuda:0'), pred_masks: tensor([[[False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "        [[False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "        [[False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "        [[False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False]]], device='cuda:0')])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instances = predictions['instances']\n",
    "instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9737498",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_masks = instances.pred_masks\n",
    "pred_classes = instances.pred_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d3838d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(234792, device='cuda:0'), tensor(234792, device='cuda:0'))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(pred_masks[1]) + torch.sum(pred_masks[3]), torch.sum(instances.pred_masks[instances.pred_classes == 15])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac7494d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02d9c78b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678ad88d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snpa",
   "language": "python",
   "name": "snpa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
