{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3d7790b-0d6c-4be8-8eaa-d353005d5fc7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data\n",
    "    \n",
    "## prepare datasource\n",
    "\n",
    "取数据集, 取[huggingface](https://huggingface.co/datasets/phiyodr/coco2017)或者[modelScope](https://www.modelscope.cn/datasets/zacbi2023/coco2017_caption/summary)\n",
    "\n",
    "### huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5df042-d6d6-4215-a004-a0e5ad44ad64",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tmp 代码临时执行区\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# llama_model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b906f4-c4d3-4f2d-a571-e65faeaa9f94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "hf_dataset = load_dataset(\"phiyodr/coco2017\")\n",
    "\n",
    "# 如果单独取 train 或者 validation\n",
    "hf_ds_train = load_dataset(\"phiyodr/coco2017\", split=\"train\")\n",
    "hf_ds_validation = load_dataset(\"phiyodr/coco2017\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99eec6ab-e00a-4538-8490-c075a02bba18",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### modelscope\n",
    "\n",
    "modelscope 的优点就是非常快, 毕竟是墙内的, 缺点是某些数据集不全，就算调用官方的api，并指定源为huggingface，也可能产生报错。\n",
    "这里的解决方案是先把huggingface的repo download下来，然后传到modelscope里，对于parquet类型的数据文件，非常友好."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0919ca-ba8d-4562-9732-0999c168d859",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from modelscope.msdatasets import MsDataset\n",
    "\n",
    "ms_ds_train = MsDataset.load('zacbi2023/coco2017_caption', subset_name='default', split='train')\n",
    "ms_ds_validation = MsDataset.load('zacbi2023/coco2017_caption', subset_name='default', split='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a7bf77-abea-4582-bb38-f03d149b376f",
   "metadata": {},
   "source": [
    "## Remap data\n",
    "\n",
    "目前我们需要的仅仅是生成horse, dog, cat类型的图像, 用简单分词然后建立新的数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a698a5-1bfb-43d6-a558-9f155f01c499",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "from modelscope import AutoTokenizer\n",
    "\n",
    "# bert 原始一点, 不会特别多的在 token 上做操作,比如增加'_' prefix or suffix\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(\"sdfdsfe/bert-base-uncased\")\n",
    "\n",
    "categories = set(['horse', 'dog', 'cat'])\n",
    "select_ds_cols = ['image_id', 'captions']\n",
    "def build_new_ds(dataset):\n",
    "    \"\"\"\n",
    "        构建新数据集,包括原来的图片 id 和 caption,caption 取 captions 中最长的,另外增加 tag,标明是怎么样的类型\n",
    "    \"\"\"\n",
    "    new_dataset = dataset.select_columns(select_ds_cols)\n",
    "    new_dataset = new_dataset.add_column(name = 'caption', column = [captions[max(range(len(captions)), key=lambda i: len(captions[i]))]  for captions in  dataset['captions']])\n",
    "    # 暂时不用存储 llama 的输出\n",
    "    # new_dataset = new_dataset.add_column(name = 'last_hidden_state', column = [torch.zeros(1).numpy().tolist() for i in range(len(new_dataset))])\n",
    "    new_dataset = new_dataset.remove_columns(['captions'])\n",
    "\n",
    "    def add_tags(caption):\n",
    "        tags = []\n",
    "        tokennized_caption = set(bert_tokenizer.tokenize(caption))\n",
    "        for category in categories:\n",
    "            if category in tokennized_caption:\n",
    "                tags.append(category)\n",
    "        return tags\n",
    "    new_dataset = new_dataset.add_column(name = 'tags', column = [add_tags(caption) for caption in new_dataset['caption']])\n",
    "    new_dataset = new_dataset.filter(lambda x: len(x['tags']) > 0)\n",
    "\n",
    "    return new_dataset\n",
    "\n",
    "ds_train = build_new_ds(ms_ds_train)\n",
    "ds_train.features, ds_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66514f43-a8e5-4f26-a328-36ae7b8e4659",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-04-05T12:23:18.983814Z",
     "iopub.status.busy": "2024-04-05T12:23:18.983210Z",
     "iopub.status.idle": "2024-04-05T12:23:18.990371Z",
     "shell.execute_reply": "2024-04-05T12:23:18.989271Z",
     "shell.execute_reply.started": "2024-04-05T12:23:18.983770Z"
    },
    "tags": []
   },
   "source": [
    "# Infer\n",
    "\n",
    "## 加载 model 和 tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a23d02c0-5eff-4e90-b065-9f886a28ecae",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "from modelscope.models import Model\n",
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.preprocessors import Preprocessor\n",
    "from modelscope.utils.constant import Tasks\n",
    "from modelscope.hub.snapshot_download import snapshot_download\n",
    "\n",
    "# 拉取到本地\n",
    "base_model_pth = r'./model'\n",
    "llama_id = r'modelscope/Llama-2-7b-ms'\n",
    "sd_id = r'AI-ModelScope/stable-diffusion-v2-1'\n",
    "llama_path = os.path.join(base_model_pth, llama_id)\n",
    "sd_path = os.path.join(base_model_pth, sd_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af06fb0-1ed6-4cab-b73b-7ec7ae915c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(llama_path):\n",
    "    snapshot_download(llama_id, cache_dir = base_model_pth)\n",
    "if not os.path.exists(sd_path):\n",
    "    snapshot_download(sd_id, cache_dir = base_model_pth) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa99752-a289-43e7-b2ad-073c196516ad",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# accelerate infer\n",
    "device = 'gpu' if torch.cuda.is_available() else 'cpu'\n",
    "device_map = 'auto'\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "from_pretrained_dict = {'device_map': device_map, 'torch_dtype' : torch_dtype, 'revision': 'v1.0.1'}\n",
    "\n",
    "def prompt_tensors_to_cuda(token_tensors):\n",
    "    for k, v in token_tensors.items():\n",
    "        token_tensors[k] = v.to('cuda')\n",
    "    return token_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3515172-5a0c-45fd-b70d-5332c6e1c147",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import LlamaModel\n",
    "\n",
    "# llama\n",
    "llama_model = LlamaModel.from_pretrained(llama_path, **from_pretrained_dict)\n",
    "llama_tokenizer = AutoTokenizer.from_pretrained(llama_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eeb870a-cb91-4766-9360-a5342330cf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sd\n",
    "# stable_diffusion_model = Model.from_pretrained(sd_path, **from_pretrained_dict)\n",
    "\n",
    "prompt = ds_train['caption'][0]\n",
    "token_tensors = llama_tokenizer(prompt, return_tensors='pt')\n",
    "llama_outputs = llama_model(**prompt_tensors_to_cuda(token_tensors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666e07ac-0c91-4613-b21f-e859c9fa375d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llama_outputs.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a34650-32d5-4ce8-8d7d-057cdfa8d5a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sd pipeline\n",
    "from diffusers import AutoPipelineForText2Image\n",
    "\n",
    "sd_pipeline = AutoPipelineForText2Image.from_pretrained(sd_path, **from_pretrained_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72a4985-b30f-438d-b55a-08511a267297",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ds_train['caption'][0]\n",
    "with torch.no_grad():\n",
    "    token_tensors = llama_tokenizer(prompt, return_tensors='pt')\n",
    "    llama_outputs = llama_model(**prompt_tensors_to_cuda(token_tensors))\n",
    "    prompt_embeds = outputs.last_hidden_state\n",
    "    sd_outputs = sd_pipeline(prompt_embeds=prompt_embeds)\n",
    "    sd_outputs.image[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011b3d8e-c898-45ba-97f4-52fe187867e2",
   "metadata": {},
   "source": [
    "# 语义分割\n",
    "\n",
    "目前sota的还是EVA模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2912f2ac-211d-4d91-8eb1-9eaf2346a9e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 8.00k/8.00k [00:00<00:00, 1.38MB/s]\n",
      "Downloading: 100%|██████████| 1.75k/1.75k [00:00<00:00, 432kB/s]\n",
      "Downloading: 100%|██████████| 1.75k/1.75k [00:00<00:00, 370kB/s]\n",
      "Downloading: 100%|██████████| 1.86k/1.86k [00:00<00:00, 498kB/s]\n",
      "Downloading: 100%|██████████| 321/321 [00:00<00:00, 77.2kB/s]\n",
      "Downloading: 100%|█████████▉| 2.22G/2.22G [00:15<00:00, 152MB/s] \n",
      "Downloading: 100%|█████████▉| 1.35G/1.35G [00:09<00:00, 152MB/s]\n",
      "Downloading: 100%|██████████| 415/415 [00:00<00:00, 110kB/s]\n",
      "Downloading: 100%|██████████| 416/416 [00:00<00:00, 113kB/s]\n",
      "Downloading: 100%|██████████| 1.82k/1.82k [00:00<00:00, 513kB/s]\n",
      "Downloading: 100%|██████████| 2.58k/2.58k [00:00<00:00, 730kB/s]\n",
      "Downloading: 100%|██████████| 2.57k/2.57k [00:00<00:00, 716kB/s]\n",
      "Downloading: 100%|██████████| 2.58k/2.58k [00:00<00:00, 716kB/s]\n",
      "Downloading: 100%|██████████| 2.60k/2.60k [00:00<00:00, 731kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model/zacbi2023/eva02'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modelscope.models import Model\n",
    "from huggingface_hub import hf_hub_download\n",
    "from modelscope import snapshot_download\n",
    "from transformers import AutoModel\n",
    "import torch\n",
    "\n",
    "eva02_model_id = r'zacbi2023/eva02/eval02/seg/eva02_L_ade_seg_upernet_sz640.pth'\n",
    "eva02_path = os.path.join(base_model_pth, eva02_model_id)\n",
    "# if not os.path.exists(llama_path):\n",
    "snapshot_download('zacbi2023/eva02', cache_dir = base_model_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4bd8d9-a768-447f-a2a7-309baf014e21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b36ea36-1052-4659-bdb6-a0dcc20f2887",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from detectron2.config import LazyConfig\n",
    "from detectron2.config import instantiate\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "\n",
    "# refer: https://github.com/baaivision/EVA/issues/11\n",
    "eval02_config_path = r'model/zacbi2023/eva02/eval02/seg/configs/eva02/upernet/upernetpro_eva02_large_24_640_slide_80k.py'\n",
    "eval02_pth_path = r'model/zacbi2023/eva02/eval02/seg/checkpoint/eva02_L_ade_seg_upernet_sz640.pth'\n",
    "\n",
    "cfg = LazyConfig.load(eval02_config_path)\n",
    "model = instantiate(cfg.model)\n",
    "\n",
    "DetectionCheckpointer(model).load(eval02_pth_path)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bb20be-ff4e-479b-a717-09a5dac04a2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e668df94-a208-4218-9602-51d2dca6a4b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
