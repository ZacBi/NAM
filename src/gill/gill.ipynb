{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-20T12:58:29.481847Z",
     "iopub.status.busy": "2024-05-20T12:58:29.481504Z",
     "iopub.status.idle": "2024-05-20T12:58:33.701485Z",
     "shell.execute_reply": "2024-05-20T12:58:33.700879Z",
     "shell.execute_reply.started": "2024-05-20T12:58:29.481816Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from os import path\n",
    "\n",
    "import torch\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.config import LazyConfig, instantiate\n",
    "from diffusers import AutoPipelineForText2Image, DiffusionPipeline\n",
    "from diffusers_interpret import StableDiffusionPipelineDetExplainer\n",
    "\n",
    "from gill import layers\n",
    "\n",
    "from torch.cuda import amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-20T12:58:33.703120Z",
     "iopub.status.busy": "2024-05-20T12:58:33.702504Z",
     "iopub.status.idle": "2024-05-20T12:58:33.705609Z",
     "shell.execute_reply": "2024-05-20T12:58:33.705101Z",
     "shell.execute_reply.started": "2024-05-20T12:58:33.703096Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = '/mnt/workspace/model'\n",
    "eva_id = 'zacbi2023/eva02'\n",
    "sd_id = 'AI-ModelScope/stable-diffusion-v1-5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-20T12:26:00.361555Z",
     "iopub.status.busy": "2024-05-20T12:26:00.361177Z",
     "iopub.status.idle": "2024-05-20T12:26:18.176819Z",
     "shell.execute_reply": "2024-05-20T12:26:18.176160Z",
     "shell.execute_reply.started": "2024-05-20T12:26:00.361531Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mbackbone.net.blocks.0.attn.qkv.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.0.attn.{rel_pos_h, rel_pos_w}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.0.mlp.fc1.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.0.mlp.fc2.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.1.attn.qkv.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.1.attn.{rel_pos_h, rel_pos_w}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.1.mlp.fc1.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.1.mlp.fc2.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.10.attn.qkv.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.10.attn.{rel_pos_h, rel_pos_w}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.10.mlp.fc1.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.10.mlp.fc2.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.11.attn.qkv.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.11.attn.{rel_pos_h, rel_pos_w}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.11.mlp.fc1.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.11.mlp.fc2.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.12.attn.qkv.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.12.attn.{rel_pos_h, rel_pos_w}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.12.mlp.fc1.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.12.mlp.fc2.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.13.attn.qkv.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.13.attn.{rel_pos_h, rel_pos_w}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.13.mlp.fc1.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.13.mlp.fc2.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.14.attn.qkv.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.14.attn.{rel_pos_h, rel_pos_w}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.14.mlp.fc1.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.14.mlp.fc2.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.15.attn.qkv.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.15.attn.{rel_pos_h, rel_pos_w}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.15.mlp.fc1.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.15.mlp.fc2.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.16.attn.qkv.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.16.attn.{rel_pos_h, rel_pos_w}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.16.mlp.fc1.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.16.mlp.fc2.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.17.attn.qkv.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.17.attn.{rel_pos_h, rel_pos_w}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.17.mlp.fc1.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.17.mlp.fc2.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.18.attn.qkv.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.18.attn.{rel_pos_h, rel_pos_w}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.18.mlp.fc1.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.18.mlp.fc2.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.19.attn.qkv.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.19.attn.{rel_pos_h, rel_pos_w}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.19.mlp.fc1.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.19.mlp.fc2.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.2.attn.qkv.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.2.attn.{rel_pos_h, rel_pos_w}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.2.mlp.fc1.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.2.mlp.fc2.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.20.attn.qkv.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.20.attn.{rel_pos_h, rel_pos_w}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.20.mlp.fc1.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.20.mlp.fc2.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.21.attn.qkv.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.21.attn.{rel_pos_h, rel_pos_w}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.21.mlp.fc1.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.21.mlp.fc2.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.22.attn.qkv.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.22.attn.{rel_pos_h, rel_pos_w}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.22.mlp.fc1.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.22.mlp.fc2.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.23.attn.qkv.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.23.attn.{rel_pos_h, rel_pos_w}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.23.mlp.fc1.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.23.mlp.fc2.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.3.attn.qkv.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.3.attn.{rel_pos_h, rel_pos_w}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.3.mlp.fc1.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.3.mlp.fc2.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.4.attn.qkv.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.4.attn.{rel_pos_h, rel_pos_w}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.4.mlp.fc1.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.4.mlp.fc2.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.5.attn.qkv.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.5.attn.{rel_pos_h, rel_pos_w}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.5.mlp.fc1.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.5.mlp.fc2.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.6.attn.qkv.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.6.attn.{rel_pos_h, rel_pos_w}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.6.mlp.fc1.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.6.mlp.fc2.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.7.attn.qkv.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.7.attn.{rel_pos_h, rel_pos_w}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.7.mlp.fc1.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.7.mlp.fc2.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.8.attn.qkv.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.8.attn.{rel_pos_h, rel_pos_w}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.8.mlp.fc1.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.8.mlp.fc2.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.9.attn.qkv.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.9.attn.{rel_pos_h, rel_pos_w}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.9.mlp.fc1.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.net.blocks.9.mlp.fc2.{bias, weight}\u001b[0m\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mpixel_mean\u001b[0m\n",
      "  \u001b[35mpixel_std\u001b[0m\n",
      "  \u001b[35mbackbone.net.rope_win.{freqs_cos, freqs_sin}\u001b[0m\n",
      "  \u001b[35mbackbone.net.rope_glb.{freqs_cos, freqs_sin}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.0.attn.{q_bias, v_bias}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.0.attn.q_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.0.attn.k_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.0.attn.v_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.0.mlp.w1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.0.mlp.w2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.0.mlp.ffn_ln.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.0.mlp.w3.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.1.attn.{q_bias, v_bias}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.1.attn.q_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.1.attn.k_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.1.attn.v_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.1.mlp.w1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.1.mlp.w2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.1.mlp.ffn_ln.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.1.mlp.w3.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.2.attn.{q_bias, v_bias}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.2.attn.q_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.2.attn.k_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.2.attn.v_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.2.mlp.w1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.2.mlp.w2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.2.mlp.ffn_ln.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.2.mlp.w3.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.3.attn.{q_bias, v_bias}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.3.attn.q_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.3.attn.k_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.3.attn.v_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.3.mlp.w1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.3.mlp.w2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.3.mlp.ffn_ln.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.3.mlp.w3.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.4.attn.{q_bias, v_bias}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.4.attn.q_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.4.attn.k_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.4.attn.v_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.4.mlp.w1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.4.mlp.w2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.4.mlp.ffn_ln.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.4.mlp.w3.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.5.attn.{q_bias, v_bias}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.5.attn.q_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.5.attn.k_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.5.attn.v_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.5.mlp.w1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.5.mlp.w2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.5.mlp.ffn_ln.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.5.mlp.w3.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.6.attn.{q_bias, v_bias}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.6.attn.q_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.6.attn.k_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.6.attn.v_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.6.mlp.w1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.6.mlp.w2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.6.mlp.ffn_ln.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.6.mlp.w3.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.7.attn.{q_bias, v_bias}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.7.attn.q_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.7.attn.k_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.7.attn.v_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.7.mlp.w1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.7.mlp.w2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.7.mlp.ffn_ln.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.7.mlp.w3.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.8.attn.{q_bias, v_bias}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.8.attn.q_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.8.attn.k_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.8.attn.v_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.8.mlp.w1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.8.mlp.w2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.8.mlp.ffn_ln.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.8.mlp.w3.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.9.attn.{q_bias, v_bias}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.9.attn.q_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.9.attn.k_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.9.attn.v_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.9.mlp.w1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.9.mlp.w2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.9.mlp.ffn_ln.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.9.mlp.w3.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.10.attn.{q_bias, v_bias}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.10.attn.q_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.10.attn.k_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.10.attn.v_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.10.mlp.w1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.10.mlp.w2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.10.mlp.ffn_ln.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.10.mlp.w3.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.11.attn.{q_bias, v_bias}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.11.attn.q_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.11.attn.k_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.11.attn.v_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.11.mlp.w1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.11.mlp.w2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.11.mlp.ffn_ln.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.11.mlp.w3.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.12.attn.{q_bias, v_bias}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.12.attn.q_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.12.attn.k_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.12.attn.v_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.12.mlp.w1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.12.mlp.w2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.12.mlp.ffn_ln.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.12.mlp.w3.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.13.attn.{q_bias, v_bias}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.13.attn.q_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.13.attn.k_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.13.attn.v_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.13.mlp.w1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.13.mlp.w2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.13.mlp.ffn_ln.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.13.mlp.w3.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.14.attn.{q_bias, v_bias}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.14.attn.q_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.14.attn.k_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.14.attn.v_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.14.mlp.w1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.14.mlp.w2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.14.mlp.ffn_ln.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.14.mlp.w3.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.15.attn.{q_bias, v_bias}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.15.attn.q_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.15.attn.k_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.15.attn.v_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.15.mlp.w1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.15.mlp.w2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.15.mlp.ffn_ln.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.15.mlp.w3.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.16.attn.{q_bias, v_bias}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.16.attn.q_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.16.attn.k_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.16.attn.v_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.16.mlp.w1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.16.mlp.w2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.16.mlp.ffn_ln.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.16.mlp.w3.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.17.attn.{q_bias, v_bias}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.17.attn.q_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.17.attn.k_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.17.attn.v_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.17.mlp.w1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.17.mlp.w2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.17.mlp.ffn_ln.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.17.mlp.w3.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.18.attn.{q_bias, v_bias}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.18.attn.q_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.18.attn.k_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.18.attn.v_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.18.mlp.w1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.18.mlp.w2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.18.mlp.ffn_ln.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.18.mlp.w3.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.19.attn.{q_bias, v_bias}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.19.attn.q_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.19.attn.k_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.19.attn.v_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.19.mlp.w1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.19.mlp.w2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.19.mlp.ffn_ln.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.19.mlp.w3.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.20.attn.{q_bias, v_bias}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.20.attn.q_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.20.attn.k_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.20.attn.v_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.20.mlp.w1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.20.mlp.w2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.20.mlp.ffn_ln.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.20.mlp.w3.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.21.attn.{q_bias, v_bias}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.21.attn.q_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.21.attn.k_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.21.attn.v_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.21.mlp.w1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.21.mlp.w2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.21.mlp.ffn_ln.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.21.mlp.w3.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.22.attn.{q_bias, v_bias}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.22.attn.q_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.22.attn.k_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.22.attn.v_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.22.mlp.w1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.22.mlp.w2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.22.mlp.ffn_ln.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.22.mlp.w3.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.23.attn.{q_bias, v_bias}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.23.attn.q_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.23.attn.k_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.23.attn.v_proj.weight\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.23.mlp.w1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.23.mlp.w2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.23.mlp.ffn_ln.{bias, weight}\u001b[0m\n",
      "  \u001b[35mbackbone.net.blocks.23.mlp.w3.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GeneralizedRCNN(\n",
       "  (backbone): SimpleFeaturePyramid(\n",
       "    (simfp_2): Sequential(\n",
       "      (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (1): LayerNorm()\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (4): Conv2d(\n",
       "        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "      (5): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (simfp_3): Sequential(\n",
       "      (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (1): Conv2d(\n",
       "        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "      (2): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (simfp_4): Sequential(\n",
       "      (0): Conv2d(\n",
       "        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "      (1): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (simfp_5): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(\n",
       "        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "      (2): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (net): ViT(\n",
       "      (patch_embed): PatchEmbed(\n",
       "        (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "      )\n",
       "      (blocks): ModuleList(\n",
       "        (0): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.013)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.026)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.039)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.052)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.065)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.078)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.091)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.104)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.117)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.130)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.143)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.157)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (13): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.170)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (14): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.183)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.196)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.209)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (17): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.222)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (18): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.235)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (19): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.248)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (20): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.261)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (21): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.274)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (22): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.287)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (23): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.300)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (top_block): LastLevelMaxPool()\n",
       "  )\n",
       "  (proposal_generator): RPN(\n",
       "    (rpn_head): StandardRPNHead(\n",
       "      (conv): Sequential(\n",
       "        (conv0): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (conv1): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (anchor_generator): DefaultAnchorGenerator(\n",
       "      (cell_anchors): BufferList()\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): CascadeROIHeads(\n",
       "    (box_pooler): ROIPooler(\n",
       "      (level_poolers): ModuleList(\n",
       "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
       "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
       "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
       "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
       "      )\n",
       "    )\n",
       "    (box_head): ModuleList(\n",
       "      (0-2): 3 x FastRCNNConvFCHead(\n",
       "        (conv1): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (norm): LayerNorm()\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (conv2): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (norm): LayerNorm()\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (conv3): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (norm): LayerNorm()\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (conv4): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (norm): LayerNorm()\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "        (fc_relu1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (box_predictor): ModuleList(\n",
       "      (0-2): 3 x FastRCNNOutputLayers(\n",
       "        (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n",
       "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (mask_pooler): ROIPooler(\n",
       "      (level_poolers): ModuleList(\n",
       "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
       "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
       "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
       "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
       "      )\n",
       "    )\n",
       "    (mask_head): MaskRCNNConvUpsampleHead(\n",
       "      (mask_fcn1): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (mask_fcn2): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (mask_fcn3): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (mask_fcn4): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (deconv_relu): ReLU()\n",
       "      (predictor): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare eva\n",
    "eva_base_path = path.join(model_path, eva_id)\n",
    "eva_coco_config_rpath = 'projects/ViTDet/configs/eva2_o365_to_coco/eva2_o365_to_coco_cascade_mask_rcnn_vitdet_l_8attn_1536_lrd0p8.py'\n",
    "eva_config_path = path.join(eva_base_path, eva_coco_config_rpath)\n",
    "\n",
    "# replace with your eva02 weights path\n",
    "eva_coco_weights_rpth = 'checkpoints/eva02_L_coco_seg_sys_o365.pth'\n",
    "eva_weights_path = path.join(eva_base_path, eva_coco_weights_rpth)\n",
    "\n",
    "custum_cfg = ['MODEL.RETINANET.SCORE_THRESH_TEST', 0.5,\n",
    "                'MODEL.ROI_HEADS.SCORE_THRESH_TEST', 0.5,\n",
    "                'MODEL.PANOPTIC_FPN.COMBINE.INSTANCES_CONFIDENCE_THRESH', 0.5,\n",
    "                'DATASETS.TEST', [],\n",
    "                'MODEL.WEIGHTS', eva_weights_path]\n",
    "eva_cfg = LazyConfig.load(eva_config_path)\n",
    "LazyConfig.apply_overrides(\n",
    "    eva_cfg, [f\"{key}={value}\" for key, value in zip(custum_cfg[::2], custum_cfg[1::2])])\n",
    "\n",
    "device = 'cuda'\n",
    "eva = instantiate(eva_cfg.model).to(device)\n",
    "DetectionCheckpointer(eva).load(eva_weights_path)\n",
    "eva.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-20T12:26:27.182910Z",
     "iopub.status.busy": "2024-05-20T12:26:27.182547Z",
     "iopub.status.idle": "2024-05-20T12:27:00.561170Z",
     "shell.execute_reply": "2024-05-20T12:27:00.560533Z",
     "shell.execute_reply.started": "2024-05-20T12:26:27.182886Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Loading pipeline components...:  86%| | 6/7 [00:30<00:05,  5.02s/it]/opt/conda/lib/python3.10/site-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
      "  warnings.warn(\n",
      "Loading pipeline components...: 100%|| 7/7 [00:30<00:00,  4.30s/it]\n"
     ]
    }
   ],
   "source": [
    "torch_dtype=torch.bfloat16\n",
    "sd_pipe = AutoPipelineForText2Image.from_pretrained(\n",
    "    path.join(model_path, sd_id), torch_dtype=torch_dtype).to(device)\n",
    "explainer = StableDiffusionPipelineDetExplainer(pipe=sd_pipe, det_model=eva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-20T12:28:49.394768Z",
     "iopub.status.busy": "2024-05-20T12:28:49.394172Z",
     "iopub.status.idle": "2024-05-20T12:28:49.941330Z",
     "shell.execute_reply": "2024-05-20T12:28:49.940782Z",
     "shell.execute_reply.started": "2024-05-20T12:28:49.394741Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GenTextHiddenFcs(\n",
       "  (gen_text_hidden_fcs): ModuleList(\n",
       "    (0): TextFcLayer(\n",
       "      (fc): Linear(in_features=4096, out_features=512, bias=True)\n",
       "      (tfm): Transformer(\n",
       "        (encoder): TransformerEncoder(\n",
       "          (layers): ModuleList(\n",
       "            (0-3): 4 x TransformerEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "              )\n",
       "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout1): Dropout(p=0.0, inplace=False)\n",
       "              (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (decoder): TransformerDecoder(\n",
       "          (layers): ModuleList(\n",
       "            (0-3): 4 x TransformerDecoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "              )\n",
       "              (multihead_attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "              )\n",
       "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout1): Dropout(p=0.0, inplace=False)\n",
       "              (dropout2): Dropout(p=0.0, inplace=False)\n",
       "              (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (model): Linear(in_features=512, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# llm(batch_size, seq_len, hidden_dim)\n",
    "raw_emb = torch.load('/mnt/workspace/data/tensor/raw_emb_tensor_cat_1.pt').to(torch_dtype)\n",
    "raw_emb.requires_grad_(True)\n",
    "# embedding img0-imge8\n",
    "gen_prefix_embs = torch.load('/mnt/workspace/data/tensor/gen_prefix_embs_tensor_cat_1.pt').to(torch_dtype)\n",
    "gen_prefix_embs.requires_grad_(True)\n",
    "\n",
    "# gill_mapper: linear + Transformer + linear\n",
    "gen_text_hidden_fcs = layers.GenTextHiddenFcs()\n",
    "gill_state_dict = torch.load('/mnt/workspace/github/gill/checkpoints/gill_opt/pretrained_ckpt.pth.tar')\n",
    "\n",
    "gen_text_hidden_fcs_state_dict = {}\n",
    "for key, val in gill_state_dict['state_dict'].items():\n",
    "    if 'gen_text_hidden_fcs' in key:\n",
    "        prefix = 'gen_text_hidden_fcs' + key.split('gen_text_hidden_fcs')[1]\n",
    "        gen_text_hidden_fcs_state_dict[prefix] = val\n",
    "gen_text_hidden_fcs.load_state_dict(gen_text_hidden_fcs_state_dict)\n",
    "gen_text_hidden_fcs.cuda()\n",
    "gen_text_hidden_fcs.to(torch_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-20T12:28:53.595384Z",
     "iopub.status.busy": "2024-05-20T12:28:53.595015Z",
     "iopub.status.idle": "2024-05-20T12:28:55.504221Z",
     "shell.execute_reply": "2024-05-20T12:28:55.503626Z",
     "shell.execute_reply.started": "2024-05-20T12:28:53.595362Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gen_emb = gen_text_hidden_fcs.gen_text_hidden_fcs[0](raw_emb, gen_prefix_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-20T12:28:56.243903Z",
     "iopub.status.busy": "2024-05-20T12:28:56.243559Z",
     "iopub.status.idle": "2024-05-20T12:29:08.725732Z",
     "shell.execute_reply": "2024-05-20T12:29:08.724747Z",
     "shell.execute_reply.started": "2024-05-20T12:28:56.243880Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/workspace/github/diffusers-interpret/src/diffusers_interpret/explainers/stable_diffusion.py:150: FutureWarning: Accessing config attribute `in_channels` directly via 'UNet2DConditionModel' object attribute is deprecated. Please access 'in_channels' over 'UNet2DConditionModel's config object instead, e.g. 'unet.config.in_channels'.\n",
      "  latents_shape = (batch_size, self.pipe.unet.in_channels, height // 8, width // 8)\n",
      "100%|| 51/51 [00:11<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating token attributions... "
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 22.20 GiB of which 2.06 GiB is free. Process 3041 has 20.13 GiB memory in use. Of the allocated memory 18.26 GiB is allocated by PyTorch, and 173.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast(dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16):\n\u001b[0;32m----> 2\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgen_emb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_inference_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_cls_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_emb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_last_diffusion_steps_to_consider_for_attributions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/workspace/github/diffusers-interpret/src/diffusers_interpret/explainer.py:196\u001b[0m, in \u001b[0;36mBasePipelineExplainer.__call__\u001b[0;34m(self, prompt, prompt_embeds, init_image, mask_image, attribution_method, explanation_2d_bounding_box, consider_special_tokens, clean_token_prefixes_and_suffixes, run_safety_checker, n_last_diffusion_steps_to_consider_for_attributions, get_images_for_all_inference_steps, output_type, **kwargs)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# Calculate primary attribution scores\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m calculate_attributions:\n\u001b[0;32m--> 196\u001b[0m     output: Union[PipelineExplainerOutput, PipelineImg2ImgExplainerOutput] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_attributions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattribution_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattribution_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_image\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_image\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask_image\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_image\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexplanation_2d_bounding_box\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexplanation_2d_bounding_box\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconsider_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconsider_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclean_token_prefixes_and_suffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclean_token_prefixes_and_suffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_last_diffusion_steps_to_consider_for_attributions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_last_diffusion_steps_to_consider_for_attributions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;66;03m# squash batch dimension\u001b[39;00m\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnsfw_content_detected\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_attributions\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpixel_attributions\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[0;32m/mnt/workspace/github/diffusers-interpret/src/diffusers_interpret/explainers/custom.py:59\u001b[0m, in \u001b[0;36mStableDiffusionPipelineDetExplainer._get_attributions\u001b[0;34m(self, output, attribution_method, tokens, text_embeddings, explanation_2d_bounding_box, consider_special_tokens, clean_token_prefixes_and_suffixes, n_last_diffusion_steps_to_consider_for_attributions, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m target_cls_id \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_cls_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     56\u001b[0m raw_embeds \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw_embeds\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     58\u001b[0m token_attributions \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradients_attribution\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpred_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattribution_algorithms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mattribution_method\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokens_attribution_method\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexplanation_2d_bounding_box\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexplanation_2d_bounding_box\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_cls_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_cls_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mraw_embeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     70\u001b[0m )\n\u001b[1;32m     72\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_process_token_attributions(\n\u001b[1;32m     73\u001b[0m     output\u001b[38;5;241m=\u001b[39moutput,\n\u001b[1;32m     74\u001b[0m     tokens\u001b[38;5;241m=\u001b[39mtokens,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     77\u001b[0m     clean_token_prefixes_and_suffixes\u001b[38;5;241m=\u001b[39mclean_token_prefixes_and_suffixes,\n\u001b[1;32m     78\u001b[0m )\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n",
      "File \u001b[0;32m/mnt/workspace/github/diffusers-interpret/src/diffusers_interpret/explainers/custom.py:146\u001b[0m, in \u001b[0;36mStableDiffusionPipelineDetExplainer.gradients_attribution\u001b[0;34m(self, pred_logits, input_embeds, attribution_algorithms, explanation_2d_bounding_box, retain_graph, target_cls_id, raw_embeds)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(input_embeds) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(attribution_algorithms)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# get mask matrix for target class\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m traget_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mask_target_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_logits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_cls_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m# Construct tuple of scalar tensors with all `pred_logits`\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# The code below is equivalent to `tuple_of_pred_logits = tuple(torch.flatten(pred_logits))`,\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m#  but for some reason the gradient calculation is way faster if the tensor is flattened like this\u001b[39;00m\n\u001b[1;32m    151\u001b[0m tuple_of_pred_logits \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/mnt/workspace/github/diffusers-interpret/src/diffusers_interpret/explainers/custom.py:111\u001b[0m, in \u001b[0;36mStableDiffusionPipelineDetExplainer._mask_target_cls\u001b[0;34m(self, image, target_cls_id)\u001b[0m\n\u001b[1;32m    104\u001b[0m image \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(\n\u001b[1;32m    105\u001b[0m     convert_PIL_to_numpy(all_images[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat16\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    108\u001b[0m )\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    110\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m: image, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheight\u001b[39m\u001b[38;5;124m\"\u001b[39m: height, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m\"\u001b[39m: width}\n\u001b[0;32m--> 111\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdet_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# offload det_model to cpu for saving gpu memory\u001b[39;00m\n\u001b[1;32m    114\u001b[0m instances \u001b[38;5;241m=\u001b[39m predictions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstances\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/detectron2/modeling/meta_arch/rcnn.py:150\u001b[0m, in \u001b[0;36mGeneralizedRCNN.forward\u001b[0;34m(self, batched_inputs)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m    batched_inputs: a list, batched outputs of :class:`DatasetMapper` .\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m        \"pred_boxes\", \"pred_classes\", \"scores\", \"pred_masks\", \"pred_keypoints\"\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_image(batched_inputs)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstances\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m batched_inputs[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/detectron2/modeling/meta_arch/rcnn.py:204\u001b[0m, in \u001b[0;36mGeneralizedRCNN.inference\u001b[0;34m(self, batched_inputs, detected_instances, do_postprocess)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining\n\u001b[1;32m    203\u001b[0m images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_image(batched_inputs)\n\u001b[0;32m--> 204\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m detected_instances \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproposal_generator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/detectron2/modeling/backbone/vit.py:489\u001b[0m, in \u001b[0;36mSimpleFeaturePyramid.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    478\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;124;03m        x: Tensor of shape (N,C,H,W). H, W must be a multiple of ``self.size_divisibility``.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;124;03m            [\"p2\", \"p3\", ..., \"p6\"].\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 489\u001b[0m     bottom_up_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    490\u001b[0m     features \u001b[38;5;241m=\u001b[39m bottom_up_features[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_feature]\n\u001b[1;32m    491\u001b[0m     results \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/detectron2/modeling/backbone/vit.py:357\u001b[0m, in \u001b[0;36mViT.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    352\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m get_abs_pos(\n\u001b[1;32m    353\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_embed, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpretrain_use_cls_token, (x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m    354\u001b[0m     )\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m--> 357\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    359\u001b[0m outputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_out_features[\u001b[38;5;241m0\u001b[39m]: x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)}\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/fairscale/nn/checkpoint/checkpoint_activations.py:191\u001b[0m, in \u001b[0;36m_checkpointed_forward\u001b[0;34m(original_forward, weak_self, offload_to_cpu, *args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m parent_ctx_dict: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moffload\u001b[39m\u001b[38;5;124m\"\u001b[39m: offload_to_cpu,\n\u001b[1;32m    180\u001b[0m }\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m# Dummy tensor with grad is used to ensure the backward pass is called. This is needed\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# when original_forward's input are non-tensor (i.e. a tuple). Using this dummy tensor\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;66;03m# avoids requiring users to set their input tensors's requires_grad flag. In the case\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# We get around this by saving the desired requires_grad value in output and\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# detaching the output if needed.\u001b[39;00m\n\u001b[0;32m--> 191\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mCheckpointFunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequires_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent_ctx_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwarg_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflat_args\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m output_requires_grad \u001b[38;5;241m=\u001b[39m parent_ctx_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_requires_grad\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;66;03m# If output should not require grad, then detach it, since otherwise it will\u001b[39;00m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;66;03m# always have requires_grad = True due to our dummy tensor input above that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;66;03m# requires_grad\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/function.py:539\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    538\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39msetup_context \u001b[38;5;241m==\u001b[39m _SingleLevelFunction\u001b[38;5;241m.\u001b[39msetup_context:\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    543\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    544\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    545\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    546\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    547\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/fairscale/nn/checkpoint/checkpoint_activations.py:283\u001b[0m, in \u001b[0;36mCheckpointFunction.forward\u001b[0;34m(ctx, dummy_tensor_requires_grad, run_function, parent_ctx_dict, kwarg_keys, *args, **kwargs)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(), enable_checkpointing():\n\u001b[1;32m    282\u001b[0m     unpacked_args, unpacked_kwargs \u001b[38;5;241m=\u001b[39m unpack_kwargs(kwarg_keys, args)\n\u001b[0;32m--> 283\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mrun_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43munpacked_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43munpacked_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m     the_module \u001b[38;5;241m=\u001b[39m unpacked_args[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# Because we run with torch.no_grad(), we can't actually access\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# outputs.requires_grad. Instead, we manually compute it by\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# checking if either the input or the module needs grads\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/detectron2/modeling/backbone/vit.py:218\u001b[0m, in \u001b[0;36mBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    215\u001b[0m     H, W \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    216\u001b[0m     x, pad_hw \u001b[38;5;241m=\u001b[39m window_partition(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_size)\n\u001b[0;32m--> 218\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# Reverse window partition\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/detectron2/modeling/backbone/vit.py:75\u001b[0m, in \u001b[0;36mAttention.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     72\u001b[0m attn \u001b[38;5;241m=\u001b[39m (q \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale) \u001b[38;5;241m@\u001b[39m k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_rel_pos:\n\u001b[0;32m---> 75\u001b[0m     attn \u001b[38;5;241m=\u001b[39m \u001b[43madd_decomposed_rel_pos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrel_pos_h\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrel_pos_w\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m attn \u001b[38;5;241m=\u001b[39m attn\u001b[38;5;241m.\u001b[39msoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     78\u001b[0m x \u001b[38;5;241m=\u001b[39m (attn \u001b[38;5;241m@\u001b[39m v)\u001b[38;5;241m.\u001b[39mview(B, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, H, W, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(B, H, W, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/detectron2/modeling/backbone/utils.py:122\u001b[0m, in \u001b[0;36madd_decomposed_rel_pos\u001b[0;34m(attn, q, rel_pos_h, rel_pos_w, q_size, k_size)\u001b[0m\n\u001b[1;32m    118\u001b[0m rel_h \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbhwc,hkc->bhwk\u001b[39m\u001b[38;5;124m\"\u001b[39m, r_q, Rh)\n\u001b[1;32m    119\u001b[0m rel_w \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbhwc,wkc->bhwk\u001b[39m\u001b[38;5;124m\"\u001b[39m, r_q, Rw)\n\u001b[1;32m    121\u001b[0m attn \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 122\u001b[0m     \u001b[43mattn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq_h\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq_w\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_h\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_w\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrel_h\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrel_w\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    123\u001b[0m )\u001b[38;5;241m.\u001b[39mview(B, q_h \u001b[38;5;241m*\u001b[39m q_w, k_h \u001b[38;5;241m*\u001b[39m k_w)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m attn\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 22.20 GiB of which 2.06 GiB is free. Process 3041 has 20.13 GiB memory in use. Of the allocated memory 18.26 GiB is allocated by PyTorch, and 173.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "with torch.cuda.amp.autocast(dtype=torch.float16):\n",
    "    output = explainer(\n",
    "        prompt_embeds=gen_emb,\n",
    "        num_inference_steps=50,\n",
    "        target_cls_id=15,\n",
    "        raw_embeds=raw_emb,\n",
    "        n_last_diffusion_steps_to_consider_for_attributions=1\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
