{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "\n",
    "import torch\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.config import LazyConfig, instantiate\n",
    "from diffusers import AutoPipelineForText2Image, DiffusionPipeline\n",
    "from diffusers_interpret import StableDiffusionPipelineDetExplainer\n",
    "\n",
    "from gill import layers\n",
    "\n",
    "from torch.cuda import amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/mnt/workspace/model'\n",
    "eva_id = 'zacbi2023/eva02'\n",
    "sd_id = 'AI-ModelScope/stable-diffusion-v1-5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== shape of rope freq torch.Size([256, 64]) ========\n",
      "======== shape of rope freq torch.Size([9216, 64]) ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mpixel_mean\u001b[0m\n",
      "  \u001b[35mpixel_std\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GeneralizedRCNN(\n",
       "  (backbone): SimpleFeaturePyramid(\n",
       "    (simfp_2): Sequential(\n",
       "      (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (1): LayerNorm()\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (4): Conv2d(\n",
       "        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "      (5): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (simfp_3): Sequential(\n",
       "      (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (1): Conv2d(\n",
       "        512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "      (2): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (simfp_4): Sequential(\n",
       "      (0): Conv2d(\n",
       "        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "      (1): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (simfp_5): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(\n",
       "        1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "      (2): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (net): ViT(\n",
       "      (patch_embed): PatchEmbed(\n",
       "        (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "      )\n",
       "      (rope_win): VisionRotaryEmbeddingFast()\n",
       "      (rope_glb): VisionRotaryEmbeddingFast()\n",
       "      (blocks): ModuleList(\n",
       "        (0): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.013)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.026)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.039)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.052)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.065)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.078)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.091)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.104)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.117)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.130)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.143)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.157)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (13): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.170)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (14): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.183)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.196)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.209)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (17): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.222)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (18): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.235)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (19): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.248)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (20): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.261)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (21): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.274)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (22): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.287)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (23): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (rope): VisionRotaryEmbeddingFast()\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.300)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): SwiGLU(\n",
       "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
       "            (act): SiLU()\n",
       "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
       "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (top_block): LastLevelMaxPool()\n",
       "  )\n",
       "  (proposal_generator): RPN(\n",
       "    (rpn_head): StandardRPNHead(\n",
       "      (conv): Sequential(\n",
       "        (conv0): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (conv1): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (anchor_generator): DefaultAnchorGenerator(\n",
       "      (cell_anchors): BufferList()\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): CascadeROIHeads(\n",
       "    (box_pooler): ROIPooler(\n",
       "      (level_poolers): ModuleList(\n",
       "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
       "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
       "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
       "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
       "      )\n",
       "    )\n",
       "    (box_head): ModuleList(\n",
       "      (0-2): 3 x FastRCNNConvFCHead(\n",
       "        (conv1): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (norm): LayerNorm()\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (conv2): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (norm): LayerNorm()\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (conv3): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (norm): LayerNorm()\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (conv4): Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (norm): LayerNorm()\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "        (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "        (fc_relu1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (box_predictor): ModuleList(\n",
       "      (0-2): 3 x FastRCNNOutputLayers(\n",
       "        (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n",
       "        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (mask_pooler): ROIPooler(\n",
       "      (level_poolers): ModuleList(\n",
       "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
       "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
       "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
       "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
       "      )\n",
       "    )\n",
       "    (mask_head): MaskRCNNConvUpsampleHead(\n",
       "      (mask_fcn1): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (mask_fcn2): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (mask_fcn3): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (mask_fcn4): Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (norm): LayerNorm()\n",
       "        (activation): ReLU()\n",
       "      )\n",
       "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (deconv_relu): ReLU()\n",
       "      (predictor): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare eva\n",
    "eva_base_path = path.join(model_path, eva_id)\n",
    "eva_coco_config_rpath = 'projects/ViTDet/configs/eva2_o365_to_coco/eva2_o365_to_coco_cascade_mask_rcnn_vitdet_l_8attn_1536_lrd0p8.py'\n",
    "eva_config_path = path.join(eva_base_path, eva_coco_config_rpath)\n",
    "\n",
    "# replace with your eva02 weights path\n",
    "eva_coco_weights_rpth = 'checkpoints/eva02_L_coco_seg_sys_o365.pth'\n",
    "eva_weights_path = path.join(eva_base_path, eva_coco_weights_rpth)\n",
    "\n",
    "custum_cfg = ['MODEL.RETINANET.SCORE_THRESH_TEST', 0.5,\n",
    "                'MODEL.ROI_HEADS.SCORE_THRESH_TEST', 0.5,\n",
    "                'MODEL.PANOPTIC_FPN.COMBINE.INSTANCES_CONFIDENCE_THRESH', 0.5,\n",
    "                'DATASETS.TEST', [],\n",
    "                'MODEL.WEIGHTS', eva_weights_path]\n",
    "eva_cfg = LazyConfig.load(eva_config_path)\n",
    "LazyConfig.apply_overrides(\n",
    "    eva_cfg, [f\"{key}={value}\" for key, value in zip(custum_cfg[::2], custum_cfg[1::2])])\n",
    "\n",
    "device = 'cuda'\n",
    "eva = instantiate(eva_cfg.model).to(device)\n",
    "DetectionCheckpointer(eva).load(eva_weights_path)\n",
    "eva.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36bc374b2d9443459e0fdc40c40f0d7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/snpa/lib/python3.8/site-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "torch_dtype=torch.bfloat16\n",
    "sd_pipe = AutoPipelineForText2Image.from_pretrained(\n",
    "    path.join(model_path, sd_id), torch_dtype=torch_dtype).to(device)\n",
    "explainer = StableDiffusionPipelineDetExplainer(pipe=sd_pipe, det_model=eva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/snpa/lib/python3.8/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GenTextHiddenFcs(\n",
       "  (gen_text_hidden_fcs): ModuleList(\n",
       "    (0): TextFcLayer(\n",
       "      (fc): Linear(in_features=4096, out_features=512, bias=True)\n",
       "      (tfm): Transformer(\n",
       "        (encoder): TransformerEncoder(\n",
       "          (layers): ModuleList(\n",
       "            (0-3): 4 x TransformerEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "              )\n",
       "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout1): Dropout(p=0.0, inplace=False)\n",
       "              (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (decoder): TransformerDecoder(\n",
       "          (layers): ModuleList(\n",
       "            (0-3): 4 x TransformerDecoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "              )\n",
       "              (multihead_attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "              )\n",
       "              (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout1): Dropout(p=0.0, inplace=False)\n",
       "              (dropout2): Dropout(p=0.0, inplace=False)\n",
       "              (dropout3): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (model): Linear(in_features=512, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_emb = torch.load('/mnt/workspace/data/tensor/raw_emb_tensor_cat_1.pt').to(torch_dtype)\n",
    "raw_emb.requires_grad_(True)\n",
    "gen_prefix_embs = torch.load('/mnt/workspace/data/tensor/gen_prefix_embs_tensor_cat_1.pt').to(torch_dtype)\n",
    "gen_prefix_embs.requires_grad_(True)\n",
    "\n",
    "gen_text_hidden_fcs = layers.GenTextHiddenFcs()\n",
    "gill_state_dict = torch.load('/mnt/workspace/github/gill/checkpoints/gill_opt/pretrained_ckpt.pth.tar')\n",
    "\n",
    "gen_text_hidden_fcs_state_dict = {}\n",
    "for key, val in gill_state_dict['state_dict'].items():\n",
    "    if 'gen_text_hidden_fcs' in key:\n",
    "        prefix = 'gen_text_hidden_fcs' + key.split('gen_text_hidden_fcs')[1]\n",
    "        gen_text_hidden_fcs_state_dict[prefix] = val\n",
    "gen_text_hidden_fcs.load_state_dict(gen_text_hidden_fcs_state_dict)\n",
    "gen_text_hidden_fcs.cuda()\n",
    "gen_text_hidden_fcs.to(torch_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_emb = gen_text_hidden_fcs.gen_text_hidden_fcs[0](raw_emb, gen_prefix_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/workspace/github/diffusers-interpret/src/diffusers_interpret/explainers/stable_diffusion.py:150: FutureWarning: Accessing config attribute `in_channels` directly via 'UNet2DConditionModel' object attribute is deprecated. Please access 'in_channels' over 'UNet2DConditionModel's config object instead, e.g. 'unet.config.in_channels'.\n",
      "  latents_shape = (batch_size, self.pipe.unet.in_channels, height // 8, width // 8)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a7da99ee6b5434387b4396aa2268709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating token attributions... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/snpa/lib/python3.8/site-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1712608851799/work/aten/src/ATen/native/TensorShape.cpp:3587.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/mnt/workspace/github/SNPA/src/gill/gill.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://dsw-gateway-cn-hangzhou.data.aliyun.com/mnt/workspace/github/SNPA/src/gill/gill.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mamp\u001b[39m.\u001b[39mautocast(dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat16):\n\u001b[0;32m----> <a href='vscode-notebook-cell://dsw-gateway-cn-hangzhou.data.aliyun.com/mnt/workspace/github/SNPA/src/gill/gill.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     output \u001b[39m=\u001b[39m explainer(\n\u001b[1;32m      <a href='vscode-notebook-cell://dsw-gateway-cn-hangzhou.data.aliyun.com/mnt/workspace/github/SNPA/src/gill/gill.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m         prompt_embeds\u001b[39m=\u001b[39;49mgen_emb,\n\u001b[1;32m      <a href='vscode-notebook-cell://dsw-gateway-cn-hangzhou.data.aliyun.com/mnt/workspace/github/SNPA/src/gill/gill.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m         num_inference_steps\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://dsw-gateway-cn-hangzhou.data.aliyun.com/mnt/workspace/github/SNPA/src/gill/gill.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m         target_cls_id\u001b[39m=\u001b[39;49m\u001b[39m15\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://dsw-gateway-cn-hangzhou.data.aliyun.com/mnt/workspace/github/SNPA/src/gill/gill.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m         raw_embeds\u001b[39m=\u001b[39;49mraw_emb\n\u001b[1;32m      <a href='vscode-notebook-cell://dsw-gateway-cn-hangzhou.data.aliyun.com/mnt/workspace/github/SNPA/src/gill/gill.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     )\n",
      "File \u001b[0;32m/mnt/workspace/github/diffusers-interpret/src/diffusers_interpret/explainer.py:196\u001b[0m, in \u001b[0;36mBasePipelineExplainer.__call__\u001b[0;34m(self, prompt, prompt_embeds, init_image, mask_image, attribution_method, explanation_2d_bounding_box, consider_special_tokens, clean_token_prefixes_and_suffixes, run_safety_checker, n_last_diffusion_steps_to_consider_for_attributions, get_images_for_all_inference_steps, output_type, **kwargs)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39m# Calculate primary attribution scores\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39mif\u001b[39;00m calculate_attributions:\n\u001b[0;32m--> 196\u001b[0m     output: Union[PipelineExplainerOutput, PipelineImg2ImgExplainerOutput] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_attributions(\n\u001b[1;32m    197\u001b[0m         output\u001b[39m=\u001b[39;49moutput,\n\u001b[1;32m    198\u001b[0m         attribution_method\u001b[39m=\u001b[39;49mattribution_method,\n\u001b[1;32m    199\u001b[0m         tokens\u001b[39m=\u001b[39;49mtokens,\n\u001b[1;32m    200\u001b[0m         text_embeddings\u001b[39m=\u001b[39;49mtext_embeddings,\n\u001b[1;32m    201\u001b[0m         init_image\u001b[39m=\u001b[39;49minit_image,\n\u001b[1;32m    202\u001b[0m         mask_image\u001b[39m=\u001b[39;49mmask_image,\n\u001b[1;32m    203\u001b[0m         explanation_2d_bounding_box\u001b[39m=\u001b[39;49mexplanation_2d_bounding_box,\n\u001b[1;32m    204\u001b[0m         consider_special_tokens\u001b[39m=\u001b[39;49mconsider_special_tokens,\n\u001b[1;32m    205\u001b[0m         clean_token_prefixes_and_suffixes\u001b[39m=\u001b[39;49mclean_token_prefixes_and_suffixes,\n\u001b[1;32m    206\u001b[0m         n_last_diffusion_steps_to_consider_for_attributions\u001b[39m=\u001b[39;49mn_last_diffusion_steps_to_consider_for_attributions,\n\u001b[1;32m    207\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    208\u001b[0m     )\n\u001b[1;32m    210\u001b[0m \u001b[39mif\u001b[39;00m batch_size \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    211\u001b[0m     \u001b[39m# squash batch dimension\u001b[39;00m\n\u001b[1;32m    212\u001b[0m     \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mnsfw_content_detected\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtoken_attributions\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpixel_attributions\u001b[39m\u001b[39m'\u001b[39m]:\n",
      "File \u001b[0;32m/mnt/workspace/github/diffusers-interpret/src/diffusers_interpret/explainers/custom.py:63\u001b[0m, in \u001b[0;36mStableDiffusionPipelineDetExplainer._get_attributions\u001b[0;34m(self, output, attribution_method, tokens, text_embeddings, explanation_2d_bounding_box, consider_special_tokens, clean_token_prefixes_and_suffixes, n_last_diffusion_steps_to_consider_for_attributions, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mif\u001b[39;00m raw_embeds \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     input_embeds \u001b[39m=\u001b[39m (raw_embeds,)\n\u001b[1;32m     62\u001b[0m token_attributions \u001b[39m=\u001b[39m (\n\u001b[0;32m---> 63\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgradients_attribution(\n\u001b[1;32m     64\u001b[0m         pred_logits\u001b[39m=\u001b[39;49moutput\u001b[39m.\u001b[39;49mimage,\n\u001b[1;32m     65\u001b[0m         input_embeds\u001b[39m=\u001b[39;49minput_embeds,\n\u001b[1;32m     66\u001b[0m         attribution_algorithms\u001b[39m=\u001b[39;49m[attribution_method\u001b[39m.\u001b[39;49mtokens_attribution_method],\n\u001b[1;32m     67\u001b[0m         explanation_2d_bounding_box\u001b[39m=\u001b[39;49mexplanation_2d_bounding_box,\n\u001b[1;32m     68\u001b[0m         target_cls_id\u001b[39m=\u001b[39;49mtarget_cls_id\n\u001b[1;32m     69\u001b[0m     )[\u001b[39m0\u001b[39m]\n\u001b[1;32m     70\u001b[0m     \u001b[39m.\u001b[39mdetach()\n\u001b[1;32m     71\u001b[0m     \u001b[39m.\u001b[39mcpu()\n\u001b[1;32m     72\u001b[0m     \u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     73\u001b[0m )\n\u001b[1;32m     75\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_post_process_token_attributions(\n\u001b[1;32m     76\u001b[0m     output\u001b[39m=\u001b[39moutput,\n\u001b[1;32m     77\u001b[0m     tokens\u001b[39m=\u001b[39mtokens,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     80\u001b[0m     clean_token_prefixes_and_suffixes\u001b[39m=\u001b[39mclean_token_prefixes_and_suffixes,\n\u001b[1;32m     81\u001b[0m )\n\u001b[1;32m     83\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose:\n",
      "File \u001b[0;32m/mnt/workspace/github/diffusers-interpret/src/diffusers_interpret/explainers/custom.py:167\u001b[0m, in \u001b[0;36mStableDiffusionPipelineDetExplainer.gradients_attribution\u001b[0;34m(self, pred_logits, input_embeds, attribution_algorithms, explanation_2d_bounding_box, retain_graph, target_cls_id)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mis_autocast_enabled():\n\u001b[1;32m    164\u001b[0m     \u001b[39m# FP16 may cause NaN gradients https://github.com/pytorch/pytorch/issues/40497\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[39m# TODO: this is still an issue, the code below does not solve it\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautocast(input_embeds[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdevice\u001b[39m.\u001b[39mtype, enabled\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 167\u001b[0m         grads \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mgrad(\n\u001b[1;32m    168\u001b[0m             tuple_of_pred_logits, input_embeds, retain_graph\u001b[39m=\u001b[39;49mretain_graph\n\u001b[1;32m    169\u001b[0m         )\n\u001b[1;32m    170\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    171\u001b[0m     grads \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mgrad(\n\u001b[1;32m    172\u001b[0m         tuple_of_pred_logits, input_embeds, retain_graph\u001b[39m=\u001b[39mretain_graph\n\u001b[1;32m    173\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/envs/snpa/lib/python3.8/site-packages/torch/autograd/__init__.py:412\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    408\u001b[0m     result \u001b[39m=\u001b[39m _vmap_internals\u001b[39m.\u001b[39m_vmap(vjp, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, allow_none_pass_through\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)(\n\u001b[1;32m    409\u001b[0m         grad_outputs_\n\u001b[1;32m    410\u001b[0m     )\n\u001b[1;32m    411\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 412\u001b[0m     result \u001b[39m=\u001b[39m _engine_run_backward(\n\u001b[1;32m    413\u001b[0m         t_outputs,\n\u001b[1;32m    414\u001b[0m         grad_outputs_,\n\u001b[1;32m    415\u001b[0m         retain_graph,\n\u001b[1;32m    416\u001b[0m         create_graph,\n\u001b[1;32m    417\u001b[0m         inputs,\n\u001b[1;32m    418\u001b[0m         allow_unused,\n\u001b[1;32m    419\u001b[0m         accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    420\u001b[0m     )\n\u001b[1;32m    421\u001b[0m \u001b[39mif\u001b[39;00m materialize_grads:\n\u001b[1;32m    422\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(\n\u001b[1;32m    423\u001b[0m         result[i] \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_tensor_like(inputs[i])\n\u001b[1;32m    424\u001b[0m         \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(inputs))\n\u001b[1;32m    425\u001b[0m     ):\n",
      "File \u001b[0;32m/opt/conda/envs/snpa/lib/python3.8/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[39m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[39mreturn\u001b[39;00m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m         t_outputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    746\u001b[0m     )  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[39mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior."
     ]
    }
   ],
   "source": [
    "with torch.cuda.amp.autocast(dtype=torch.float16):\n",
    "    output = explainer(\n",
    "        prompt_embeds=gen_emb,\n",
    "        num_inference_steps=1,\n",
    "        target_cls_id=15,\n",
    "        raw_embeds=raw_emb\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4096])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llava",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
